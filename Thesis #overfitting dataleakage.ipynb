{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPwHT662lhuqW+6u9/A6E3C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samer-glitch/samerelhajjhassan/blob/main/Thesis%20%23overfitting%20dataleakage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NP2x7lU4nxn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "f7wR_Gan4oN7",
        "outputId": "e88973e3-41bd-4deb-dd38-76b5a7e6df9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-99d5418b-ee2a-4c6f-9a7a-b967bb735e32\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-99d5418b-ee2a-4c6f-9a7a-b967bb735e32\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WYZLQlam4opA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier, BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.tree import DecisionTreeClassifier  # Import missing classifier\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "def record_time(step_name, overall_start_time):\n",
        "    print(f\"{step_name} - Time Elapsed: {datetime.datetime.now() - overall_start_time}\")\n",
        "\n",
        "def label_traffic_advanced(df):\n",
        "    # Define adjusted thresholds based on typical network traffic characteristics\n",
        "    normal_protocols = [6, 17, 1]  # TCP, UDP, and ICMP are common protocols\n",
        "    normal_port_range = set(range(0, 65536))  # All ports are included\n",
        "    normal_pkt_count_max = 50000  # A higher limit to account for active connections\n",
        "    normal_octet_count_max = 5000000  # Increased to allow for larger data transfers\n",
        "    normal_packet_size_range = range(0, 6000)  # Ethernet standard MTU size\n",
        "    normal_flow_duration_range = range(0, 7200000)  # Extended to 2 hours\n",
        "    normal_piat_range = range(0, 30000)  # Extended to 30 seconds\n",
        "    max_timestamp = int(1e12)  # Assuming timestamp in milliseconds\n",
        "\n",
        "    # Initialize the traffic_label column\n",
        "    df['traffic_label'] = 'normal'\n",
        "\n",
        "    # Iterate through each row\n",
        "    for index, row in df.iterrows():\n",
        "        # Check conditions for each feature\n",
        "        if row['proto'] not in normal_protocols:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'proto' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['flowEndReason'] == 1:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'flowEndReason' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['src_port'] not in normal_port_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'src_port' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['dst_port'] not in normal_port_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'dst_port' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['pktTotalCount'] > normal_pkt_count_max:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'pktTotalCount' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['octetTotalCount'] > normal_octet_count_max:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'octetTotalCount' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['min_ps'] not in normal_packet_size_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'min_ps' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['max_ps'] not in normal_packet_size_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'max_ps' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['avg_ps'] not in normal_packet_size_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'avg_ps' condition met\")\n",
        "\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "\n",
        "        if row['std_dev_ps'] not in normal_packet_size_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'std_dev_ps' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['flowDuration'] not in normal_flow_duration_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'flowDuration' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['min_piat'] not in normal_piat_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'min_piat' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['max_piat'] not in normal_piat_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'max_piat' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['avg_piat'] not in normal_piat_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'avg_piat' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['std_dev_piat'] not in normal_piat_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'std_dev_piat' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['flowStart'] < 0 or row['flowStart'] > max_timestamp:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'flowStart' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['flowEnd'] < 0 or row['flowEnd'] > max_timestamp:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'flowEnd' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['flowEnd'] < row['flowStart']:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'flowEnd' < 'flowStart' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        # Checks for 'f_' prefixed features\n",
        "        if row['f_pktTotalCount'] > normal_pkt_count_max:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'f_pktTotalCount' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['f_octetTotalCount'] > normal_octet_count_max:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'f_octetTotalCount' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['f_min_ps'] not in normal_packet_size_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'f_min_ps' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['f_max_ps'] not in normal_packet_size_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'f_max_ps' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['f_avg_ps'] not in normal_packet_size_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'f_avg_ps' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['f_std_dev_ps'] not in normal_packet_size_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'f_std_dev_ps' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['f_flowDuration'] not in normal_flow_duration_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'f_flowDuration' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['f_min_piat'] not in normal_piat_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'f_min_piat' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['f_max_piat'] not in normal_piat_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'f_max_piat' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['f_avg_piat'] not in normal_piat_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'f_avg_piat' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['f_std_dev_piat'] not in normal_piat_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'f_std_dev_piat' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        # Checks for 'b_' prefixed features\n",
        "        if row['b_pktTotalCount'] > normal_pkt_count_max:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'b_pktTotalCount' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['b_octetTotalCount'] > normal_octet_count_max:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'b_octetTotalCount' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['b_min_ps'] not in normal_packet_size_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'b_min_ps' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['b_max_ps'] not in normal_packet_size_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'b_max_ps' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['b_avg_ps'] not in normal_packet_size_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'b_avg_ps' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['b_std_dev_ps'] not in normal_packet_size_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'b_std_dev_ps' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['b_flowDuration'] not in normal_flow_duration_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'b_flowDuration' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['b_min_piat'] not in normal_piat_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'b_min_piat' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['b_max_piat'] not in normal_piat_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'b_max_piat' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['b_avg_piat'] not in normal_piat_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'b_avg_piat' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        if row['b_std_dev_piat'] not in normal_piat_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'b_std_dev_piat' condition met\")\n",
        "            continue  # Move to the next row if the condition is met\n",
        "\n",
        "        # Add the new condition for category, application_protocol, and web_service\n",
        "        if row['category'] == 'Unspecified' and row['application_protocol'] == 'Unknown' and row['web_service'] == 'Unknown':\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            print(f\"Row {index}: 'category', 'application_protocol', 'web_service' condition met\")\n",
        "\n",
        "    # Print the count of instances in each class after labeling\n",
        "    label_counts = df['traffic_label'].value_counts()\n",
        "    print(\"Label distribution after labeling:\")\n",
        "    print(label_counts)\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('Unicauca-dataset-April-June-2019-Network-flows-25000rows(ALLFEATURES).csv')\n",
        "overall_start_time = datetime.datetime.now()\n",
        "record_time(\"Dataset Loaded\", overall_start_time)\n",
        "\n",
        "\n",
        "# Call your labeling function\n",
        "df = label_traffic_advanced(df)\n",
        "record_time(\"Labeling Function Applied\", overall_start_time)\n",
        "\n",
        "# Assuming 'traffic_label' is categorical and needs to be encoded\n",
        "label_encoder = LabelEncoder()\n",
        "df['category_encoded'] = label_encoder.fit_transform(df['traffic_label'])\n",
        "record_time(\"Categorical Labels Encoded\", overall_start_time)\n",
        "\n",
        "# Drop columns\n",
        "X = df.drop(columns=['traffic_label', 'category_encoded'])\n",
        "y = df['category_encoded']\n",
        "record_time(\"Features and Target Variable Defined\", overall_start_time)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "record_time(\"Data Split into Train and Test Sets\", overall_start_time)\n",
        "\n",
        "non_numeric_columns = X_train.select_dtypes(exclude=[np.number]).columns\n",
        "X_train = X_train.drop(non_numeric_columns, axis=1)\n",
        "X_test = X_test.drop(non_numeric_columns, axis=1)\n",
        "record_time(\"Non-numeric Columns Handled\", overall_start_time)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "record_time(\"Preprocessing Applied\", overall_start_time)\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Create an imputer object with a median filling strategy\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Apply imputation to the training data\n",
        "X_train_imputed = imputer.fit_transform(X_train_scaled)\n",
        "\n",
        "# Apply the same imputation to the test data\n",
        "X_test_imputed = imputer.transform(X_test_scaled)\n",
        "\n",
        "# Now apply SMOTE\n",
        "#sm = SMOTE(random_state=42)\n",
        "#X_train_res, y_train_res = sm.fit_resample(X_train_imputed, y_train)\n",
        "\n",
        "\n",
        "# Models\n",
        "# RandomForestClassifier adjustment\n",
        "rf_clf = RandomForestClassifier(n_estimators=50, max_features='sqrt', random_state=42)\n",
        "# BaggingClassifier adjustment\n",
        "bag_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "# LightGBMClassifier adjustment\n",
        "lgbm_clf = LGBMClassifier(random_state=42, max_depth=6, min_data_in_leaf=20, num_leaves=31)\n",
        "lr_clf = LogisticRegression(random_state=42)\n",
        "ab_clf = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
        "gb_clf = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "# Voting Classifier\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', lr_clf),\n",
        "        ('lgbm', lgbm_clf),\n",
        "        ('rf', rf_clf),\n",
        "        ('ab', ab_clf),\n",
        "        ('gb', gb_clf),\n",
        "        ('bag', bag_clf)\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "# Fit Models\n",
        "for clf in (lr_clf, lgbm_clf, rf_clf, ab_clf, gb_clf, bag_clf, voting_clf):\n",
        "    clf.fit(X_train_res, y_train_res)\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "# Hyperparameter tuning example for RandomForestClassifier\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth' : [4, 5, 6, 7, 8],\n",
        "    'criterion' :['gini', 'entropy']\n",
        "}\n",
        "\n",
        "CV_rfc = GridSearchCV(estimator=rf_clf, param_grid=param_grid, cv=5)\n",
        "CV_rfc.fit(X_train_res, y_train_res)\n",
        "print(\"Best parameters for RandomForestClassifier:\", CV_rfc.best_params_)\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model):\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test_scaled)[:,1])\n",
        "    auc_score = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure()\n",
        "    lw = 2\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % auc_score)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    return conf_matrix, auc_score\n",
        "\n",
        "for clf in (lr_clf, lgbm_clf, rf_clf, ab_clf, gb_clf, bag_clf, voting_clf):\n",
        "    print(clf.__class__.__name__)\n",
        "    conf_matrix, auc_score = evaluate_model(clf)\n",
        "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "    print(\"AUC Score:\", auc_score)\n",
        "\n",
        "print(\"\\nProcess Completed - Time:\", datetime.datetime.now() - overall_start_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "211cde0j6t4K",
        "outputId": "4d3cbf66-14f2-40f2-8e62-d3566f10b445"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded - Time Elapsed: 0:00:00.000077\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'avg_ps' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-5eb4ffc0043a>\u001b[0m in \u001b[0;36m<cell line: 264>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;31m# Call your labeling function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_traffic_advanced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0mrecord_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Labeling Function Applied\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverall_start_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-5eb4ffc0043a>\u001b[0m in \u001b[0;36mlabel_traffic_advanced\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_ps'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_packet_size_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'traffic_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'malicious'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Row {index}: 'avg_ps' condition met\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_ps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# Move to the next row if the condition is met\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'avg_ps' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "X4Xf1SuG_Wdq",
        "outputId": "52192f07-4a4a-4221-c8f6-f85c6c9ecc21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-be1cd86b-bb7d-4207-822c-8936a0bf520a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-be1cd86b-bb7d-4207-822c-8936a0bf520a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Unicauca-dataset-April-June-2019-Network-flows-10000rows(ALLFEATURES).csv to Unicauca-dataset-April-June-2019-Network-flows-10000rows(ALLFEATURES).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier, BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def record_time(step_name, overall_start_time):\n",
        "    print(f\"{step_name} - Time Elapsed: {datetime.datetime.now() - overall_start_time}\")\n",
        "\n",
        "def label_traffic_advanced(df):\n",
        "    # Define normal thresholds based on typical network traffic characteristics in a university and a software company\n",
        "    normal_protocols = {6, 17, 1}  # Common protocols: TCP, UDP, ICMP\n",
        "    normal_port_range = set(range(0, 1024))  # Well-known ports, often targeted in attacks\n",
        "    high_pkt_count_threshold = 10000  # High packet count could indicate scanning or DoS attacks\n",
        "    high_data_volume_threshold = 10**7  # Threshold for data transfer volume (e.g., 10 MB)\n",
        "    short_flow_duration_threshold = 500  # Very short flows (in ms) might be scans\n",
        "    long_flow_duration_threshold = 3600000  # 1 hour, unusual long flows could be exfiltration\n",
        "    suspicious_packet_size = 1500  # Standard MTU size for Ethernet, larger could be unusual\n",
        "    high_inter_arrival_time = 1000  # Max acceptable packet inter-arrival time in ms\n",
        "    low_inter_arrival_time = 10  # Min acceptable packet inter-arrival time in ms\n",
        "    high_flow_rate = 10000  # Threshold for flow rate (packets per second)\n",
        "\n",
        "    df['traffic_label'] = 'normal'\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        # Check for uncommon protocols\n",
        "        if row['proto'] not in normal_protocols:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            continue\n",
        "\n",
        "        # Check for traffic on unusual ports\n",
        "        if row['src_port'] not in normal_port_range or row['dst_port'] not in normal_port_range:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            continue\n",
        "\n",
        "        # High packet counts and data volumes\n",
        "        if row['pktTotalCount'] > high_pkt_count_threshold or row['octetTotalCount'] > high_data_volume_threshold:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            continue\n",
        "\n",
        "        # Unusual flow durations\n",
        "        if row['flowDuration'] < short_flow_duration_threshold or row['flowDuration'] > long_flow_duration_threshold:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            continue\n",
        "\n",
        "        # Packet sizes and inter-arrival times\n",
        "        if row['max_ps'] > suspicious_packet_size or row['min_ps'] > suspicious_packet_size:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            continue\n",
        "\n",
        "        if row['avg_piat'] > high_inter_arrival_time or row['avg_piat'] < low_inter_arrival_time:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            continue\n",
        "\n",
        "        # Flow rate\n",
        "        if row['flowDuration'] > 0 and (row['pktTotalCount'] / (row['flowDuration'] / 1000)) > high_flow_rate:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "            continue\n",
        "\n",
        "        # Additional checks can be added based on more specific characteristics of network traffic\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "df = pd.read_csv('Unicauca-dataset-April-June-2019-Network-flows-5000rows(ALLFEATURES).csv')\n",
        "overall_start_time = datetime.datetime.now()\n",
        "\n",
        "df = label_traffic_advanced(df)\n",
        "record_time(\"Labeling Function Applied\", overall_start_time)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['category_encoded'] = label_encoder.fit_transform(df['traffic_label'])\n",
        "record_time(\"Categorical Labels Encoded\", overall_start_time)\n",
        "\n",
        "# Prepare data for model training\n",
        "X = df.drop(columns=['traffic_label', 'category_encoded'])\n",
        "y = df['category_encoded']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "record_time(\"Data Split into Train and Test Sets\", overall_start_time)\n",
        "\n",
        "# Impute and scale the data\n",
        "numeric_columns = X_train.select_dtypes(include=[np.number]).columns\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(X_train[numeric_columns])\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_test_imputed = imputer.transform(X_test[numeric_columns])\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "\n",
        "# Apply SMOTE to the training data\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "# Define and evaluate models using cross-validation\n",
        "models = {\n",
        "    \"LogisticRegression\": LogisticRegression(random_state=42),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(n_estimators=50, max_features='sqrt', random_state=42),\n",
        "    \"AdaBoostClassifier\": AdaBoostClassifier(n_estimators=50, random_state=42),\n",
        "    \"GradientBoostingClassifier\": GradientBoostingClassifier(n_estimators=50, random_state=42),\n",
        "    \"BaggingClassifier\": BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42),\n",
        "    \"VotingClassifier\": VotingClassifier(\n",
        "        estimators=[\n",
        "            ('lr', LogisticRegression(random_state=42)),\n",
        "            ('rf', RandomForestClassifier(n_estimators=50, max_features='sqrt', random_state=42)),\n",
        "            ('ab', AdaBoostClassifier(n_estimators=50, random_state=42)),\n",
        "            ('gb', GradientBoostingClassifier(n_estimators=50, random_state=42)),\n",
        "            ('bag', BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42))\n",
        "        ],\n",
        "        voting='soft'\n",
        "    )\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    cv_scores = cross_val_score(model, X_train_res, y_train_res, cv=5, scoring='accuracy')\n",
        "    print(f\"{model_name}: Mean CV Accuracy: {cv_scores.mean()}, Standard Deviation: {cv_scores.std()}\")\n",
        "\n",
        "# Best parameter tuning for RandomForestClassifier\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth': [4, 5, 6, 7, 8],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "CV_rfc = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid, cv=5)\n",
        "CV_rfc.fit(X_train_res, y_train_res)\n",
        "print(\"Best parameters for RandomForestClassifier:\", CV_rfc.best_params_)\n",
        "\n",
        "print(\"\\nProcess Completed - Time:\", datetime.datetime.now() - overall_start_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "W6aS5j8P_MjN",
        "outputId": "378341b3-f6c8-4dfb-a816-6120a89e675e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labeling Function Applied - Time Elapsed: 0:00:00.794568\n",
            "Categorical Labels Encoded - Time Elapsed: 0:00:00.797798\n",
            "Data Split into Train and Test Sets - Time Elapsed: 0:00:00.808536\n",
            "LogisticRegression: Mean CV Accuracy: 0.999874686716792, Standard Deviation: 0.00015347680092626088\n",
            "RandomForestClassifier: Mean CV Accuracy: 1.0, Standard Deviation: 0.0\n",
            "AdaBoostClassifier: Mean CV Accuracy: 1.0, Standard Deviation: 0.0\n",
            "GradientBoostingClassifier: Mean CV Accuracy: 1.0, Standard Deviation: 0.0\n",
            "BaggingClassifier: Mean CV Accuracy: 1.0, Standard Deviation: 0.0\n",
            "VotingClassifier: Mean CV Accuracy: 1.0, Standard Deviation: 0.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9fa8b0737a99>\u001b[0m in \u001b[0;36m<cell line: 138>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m }\n\u001b[1;32m    137\u001b[0m \u001b[0mCV_rfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0mCV_rfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters for RandomForestClassifier:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCV_rfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models and plot confusion matrices and ROC curves\n",
        "for clf, name in [(lr_clf, 'Logistic Regression'), (rf_clf, 'Random Forest'), (ab_clf, 'AdaBoost'), (gb_clf, 'Gradient Boosting')]:\n",
        "    # Predictions and probabilities\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "    y_pred_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plot_confusion_matrix(cm, name)\n",
        "\n",
        "    # ROC curve\n",
        "    plot_roc_curve(y_test, y_pred_proba, name)\n",
        "\n",
        "# Calculate accuracy and F1-score for each model\n",
        "lr_accuracy, lr_f1 = accuracy_score(y_test, lr_clf.predict(X_test_scaled)), f1_score(y_test, lr_clf.predict(X_test_scaled))\n",
        "rf_accuracy, rf_f1 = accuracy_score(y_test, rf_clf.predict(X_test_scaled)), f1_score(y_test, rf_clf.predict(X_test_scaled))\n",
        "ab_accuracy, ab_f1 = accuracy_score(y_test, ab_clf.predict(X_test_scaled)), f1_score(y_test, ab_clf.predict(X_test_scaled))\n",
        "gb_accuracy, gb_f1 = accuracy_score(y_test, gb_clf.predict(X_test_scaled)), f1_score(y_test, gb_clf.predict(X_test_scaled))\n",
        "\n",
        "# Print the results\n",
        "print(\"\\nLogistic Regression Classifier:\\nAccuracy:\", lr_accuracy, \"\\nF1-Score:\", lr_f1)\n",
        "print(\"\\nRandom Forest Classifier:\\nAccuracy:\", rf_accuracy, \"\\nF1-Score:\", rf_f1)\n",
        "print(\"\\nAdaBoost Classifier:\\nAccuracy:\", ab_accuracy, \"\\nF1-Score:\", ab_f1)\n",
        "print(\"\\nGradient Boosting Classifier:\\nAccuracy:\", gb_accuracy, \"\\nF1-Score:\", gb_f1)\n",
        "print(\"\\nProcess Completed - Time:\", datetime.datetime.now() - overall_start_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "eIEZUWkkktFt",
        "outputId": "f149e979-20b8-4fa5-fda9-8c09d2f4438a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plot_confusion_matrix' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-9d767f7e3290>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# ROC curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_confusion_matrix' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the count of instances in each class after labeling\n",
        "label_counts = df['traffic_label'].value_counts()\n",
        "print(\"Label distribution after labeling:\")\n",
        "print(label_counts)\n",
        "\n",
        "print(df['category_encoded'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlp3gHkMAHYV",
        "outputId": "a9fd6927-5d8f-4ea7-cef4-37ba5cd2eef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label distribution after labeling:\n",
            "malicious    8054\n",
            "normal       1946\n",
            "Name: traffic_label, dtype: int64\n",
            "0    8054\n",
            "1    1946\n",
            "Name: category_encoded, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display basic statistics\n",
        "print(\"Statistics for avg_piat:\")\n",
        "print(df['avg_piat'].describe())\n",
        "\n",
        "print(\"\\nStatistics for min_piat:\")\n",
        "print(df['min_piat'].describe())\n",
        "\n",
        "print(\"\\nStatistics for max_piat:\")\n",
        "print(df['max_piat'].describe())\n",
        "import seaborn as sns\n",
        "# Plotting distributions\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.histplot(df['avg_piat'], kde=True, bins=30)\n",
        "plt.title('Distribution of avg_piat')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.histplot(df['min_piat'], kde=True, bins=30)\n",
        "plt.title('Distribution of min_piat')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.histplot(df['max_piat'], kde=True, bins=30)\n",
        "plt.title('Distribution of max_piat')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D1GKP75PD7f5",
        "outputId": "41cdd863-8719-4e20-a4ad-05e9c879d13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics for avg_piat:\n",
            "count     49.000000\n",
            "mean      38.150012\n",
            "std      119.770222\n",
            "min        0.000000\n",
            "25%        0.000659\n",
            "50%        0.031510\n",
            "75%       21.531847\n",
            "max      600.021289\n",
            "Name: avg_piat, dtype: float64\n",
            "\n",
            "Statistics for min_piat:\n",
            "count     49.000000\n",
            "mean      24.949830\n",
            "std      119.869693\n",
            "min        0.000000\n",
            "25%        0.000077\n",
            "50%        0.000433\n",
            "75%        0.000760\n",
            "max      600.014446\n",
            "Name: min_piat, dtype: float64\n",
            "\n",
            "Statistics for max_piat:\n",
            "count     49.000000\n",
            "mean     104.284074\n",
            "std      165.964596\n",
            "min        0.000000\n",
            "25%        0.000668\n",
            "50%        0.379798\n",
            "75%      198.656500\n",
            "max      600.028202\n",
            "Name: max_piat, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display basic statistics\n",
        "print(\"Statistics for flowDuration:\")\n",
        "print(df['flowDuration'].describe())\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "# Plotting distributions\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.histplot(df['flowDuration'], kde=True, bins=30)\n",
        "plt.title('Distribution of flowDuration')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "H7VDVzI7GsJD",
        "outputId": "9e5796f4-dc5e-46f2-b3b0-de7125e80d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics for avg_piat:\n",
            "count      49.000000\n",
            "mean      401.888065\n",
            "std       665.791649\n",
            "min         0.000000\n",
            "25%         0.000668\n",
            "50%         0.752857\n",
            "75%       304.808016\n",
            "max      1756.997627\n",
            "Name: flowDuration, dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Distribution of flowDuration')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Function to record the current time since the overall start\n",
        "def record_time(step_name, overall_start_time):\n",
        "    print(f\"{step_name} - Time Elapsed: {datetime.datetime.now() - overall_start_time}\")\n",
        "\n",
        "# Function to plot the confusion matrix\n",
        "def plot_confusion_matrix(cm, classifier_name):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix for {classifier_name}')\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "\n",
        "# Function to plot ROC curve\n",
        "def plot_roc_curve(y_true, y_scores, classifier_name):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve for {classifier_name}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('Unicauca-dataset-April-June-2019-Network-flows-50000rows(ALLFEATURES).csv')\n",
        "\n",
        "# Start the overall timer\n",
        "overall_start_time = datetime.datetime.now()\n",
        "record_time(\"Dataset Loaded\", overall_start_time)\n",
        "\n",
        "def label_traffic(df):\n",
        "    # Define normal thresholds\n",
        "    normal_protocols = [6, 17, 1]  # TCP and UDP\n",
        "    normal_port_range = set(range(0, 49152))\n",
        "    normal_pkt_count_max = 2000\n",
        "    normal_octet_count_max = 1000000\n",
        "    normal_packet_size_range = range(20, 1500)\n",
        "    normal_flow_duration_range = range(50, 3600000)  # 50 ms to 1 hour\n",
        "    normal_piat_range = range(0, 10000)  # 0 to 10 seconds\n",
        "    max_timestamp = int(1e12)  # Assuming timestamp in milliseconds\n",
        "\n",
        "    # Initialize the traffic_label column\n",
        "    df['traffic_label'] = 'normal'\n",
        "\n",
        "    # Vectorized conditions\n",
        "# Vectorized conditions\n",
        "    df.loc[~df['proto'].isin(normal_protocols), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['flowEndReason'] == 1, 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['src_port'].isin(normal_port_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['dst_port'].isin(normal_port_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['pktTotalCount'] > normal_pkt_count_max, 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['octetTotalCount'] > normal_octet_count_max, 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['min_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['max_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['avg_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['flowDuration'].isin(normal_flow_duration_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['min_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['max_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['avg_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[(df['flowStart'] < 0) | (df['flowStart'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[(df['flowEnd'] < 0) | (df['flowEnd'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['flowEnd'] < df['flowStart'], 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # Process forward and backward flow features\n",
        "    for prefix in ['f_', 'b_']:\n",
        "        df.loc[df[prefix + 'pktTotalCount'] > normal_pkt_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[df[prefix + 'octetTotalCount'] > normal_octet_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'min_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'max_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'flowDuration'].isin(normal_flow_duration_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'min_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'max_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # IP Address checks\n",
        "    normal_src_ip_ranges = ['192.168.', '10.', '172.16.', '172.17.', '172.18.', '172.19.', '172.20.', '172.21.', '172.22.', '172.23.', '172.24.', '172.25.', '172.26.', '172.27.', '172.28.', '172.29.', '172.30.', '172.31.']\n",
        "    df.loc[df['src_ip'].apply(lambda ip: any(ip.startswith(range) for range in normal_src_ip_ranges)), 'traffic_label'] = 'normal'\n",
        "    df.loc[df['dst_ip'].apply(lambda ip: any(ip.startswith(range) for range in normal_src_ip_ranges)), 'traffic_label'] = 'normal'\n",
        "\n",
        "    # Web service, application protocol, and category checks\n",
        "    normal_web_services = ['Google', 'Microsoft', 'HTTP', 'DNS', 'Amazon', 'MSN', 'TLS', 'Yahoo', 'DHCP', 'WindowsUpdate', 'NetBIOS', 'RX', 'MS_OneDrive', 'GMail', 'Dropbox', 'GoogleServices', 'ICMP']\n",
        "    normal_application_protocols = ['HTTP', 'TLS', 'DNS', 'QUIC', 'IMAPS', 'STUN', 'SMTPS', 'POPS', 'Skype', 'SMBv23', 'NetBIOS', 'RDP', 'ApplePush', 'MQTT']\n",
        "    normal_categories = ['Network', 'Web', 'SoftwareUpdate', 'RPC', 'System', 'Cloud', 'Mail', 'FTP', 'VPN', 'RemoteAccess']\n",
        "    df.loc[~df['web_service'].isin(normal_web_services), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['application_protocol'].isin(normal_application_protocols), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['category'].isin(normal_categories), 'traffic_label'] = 'malicious'\n",
        "\n",
        "\n",
        "    return df\n",
        "# Apply the labeling function to the DataFrame\n",
        "df = label_traffic(df)\n",
        "record_time(\"Labeling Function Applied\", overall_start_time)\n",
        "\n",
        "# Encoding the categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['category_encoded'] = label_encoder.fit_transform(df['traffic_label'])\n",
        "record_time(\"Categorical Labels Encoded\", overall_start_time)\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop(columns=['traffic_label', 'category_encoded'])\n",
        "y = df['category_encoded']\n",
        "record_time(\"Features and Target Variable Defined\", overall_start_time)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "record_time(\"Data Split into Train and Test Sets\", overall_start_time)\n",
        "\n",
        "# Identify non-numeric columns\n",
        "non_numeric_columns = X_train.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "# Remove non-numeric columns for simplicity\n",
        "X_train = X_train.drop(non_numeric_columns, axis=1)\n",
        "X_test = X_test.drop(non_numeric_columns, axis=1)\n",
        "record_time(\"Non-numeric Columns Handled\", overall_start_time)\n",
        "\n",
        "# Apply preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "record_time(\"Preprocessing Applied\", overall_start_time)\n",
        "\n",
        "# Define and fit the classifiers\n",
        "lr_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "rf_clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "ab_clf = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
        "gb_clf = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "lr_clf.fit(X_train_scaled, y_train)\n",
        "rf_clf.fit(X_train_scaled, y_train)\n",
        "ab_clf.fit(X_train_scaled, y_train)\n",
        "gb_clf.fit(X_train_scaled, y_train)\n",
        "record_time(\"Classifiers Fitted\", overall_start_time)\n",
        "\n",
        "# Evaluate models and plot confusion matrices and ROC curves\n",
        "for clf, name in [(lr_clf, 'Logistic Regression'), (rf_clf, 'Random Forest'), (ab_clf, 'AdaBoost'), (gb_clf, 'Gradient Boosting')]:\n",
        "    # Predictions and probabilities\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "    y_pred_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plot_confusion_matrix(cm, name)\n",
        "\n",
        "    # ROC curve\n",
        "    plot_roc_curve(y_test, y_pred_proba, name)\n",
        "\n",
        "# Calculate accuracy and F1-score for each model\n",
        "lr_accuracy, lr_f1 = accuracy_score(y_test, lr_clf.predict(X_test_scaled)), f1_score(y_test, lr_clf.predict(X_test_scaled))\n",
        "rf_accuracy, rf_f1 = accuracy_score(y_test, rf_clf.predict(X_test_scaled)), f1_score(y_test, rf_clf.predict(X_test_scaled))\n",
        "ab_accuracy, ab_f1 = accuracy_score(y_test, ab_clf.predict(X_test_scaled)), f1_score(y_test, ab_clf.predict(X_test_scaled))\n",
        "gb_accuracy, gb_f1 = accuracy_score(y_test, gb_clf.predict(X_test_scaled)), f1_score(y_test, gb_clf.predict(X_test_scaled))\n",
        "\n",
        "# Print the results\n",
        "print(\"\\nLogistic Regression Classifier:\\nAccuracy:\", lr_accuracy, \"\\nF1-Score:\", lr_f1)\n",
        "print(\"\\nRandom Forest Classifier:\\nAccuracy:\", rf_accuracy, \"\\nF1-Score:\", rf_f1)\n",
        "print(\"\\nAdaBoost Classifier:\\nAccuracy:\", ab_accuracy, \"\\nF1-Score:\", ab_f1)\n",
        "print(\"\\nGradient Boosting Classifier:\\nAccuracy:\", gb_accuracy, \"\\nF1-Score:\", gb_f1)\n",
        "print(\"\\nProcess Completed - Time:\", datetime.datetime.now() - overall_start_time)"
      ],
      "metadata": {
        "id": "jWmjsLRy2je9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Function to record the current time since the overall start\n",
        "def record_time(step_name, overall_start_time):\n",
        "    print(f\"{step_name} - Time Elapsed: {datetime.datetime.now() - overall_start_time}\")\n",
        "\n",
        "# Start the overall timer\n",
        "overall_start_time = datetime.datetime.now()\n",
        "record_time(\"Dataset Loaded\", overall_start_time)\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(cm, classifier_name):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix for {classifier_name}')\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "\n",
        "# Function to plot ROC curve\n",
        "def plot_roc_curve(y_true, y_scores, classifier_name):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve for {classifier_name}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('Unicauca-dataset-April-June-2019-Network-flows-50000rows(ALLFEATURES).csv')\n",
        "overall_start_time = datetime.datetime.now()\n",
        "record_time(\"Dataset Loaded\", overall_start_time)\n",
        "\n",
        "# Convert Unix timestamps to datetime objects\n",
        "df['flowStart'] = pd.to_datetime(df['flowStart'], unit='s')\n",
        "df['flowEnd'] = pd.to_datetime(df['flowEnd'], unit='s')\n",
        "max_timestamp = pd.to_datetime('now')  # Define max_timestamp\n",
        "\n",
        "# Extracting temporal features\n",
        "df['flowStart_second'] = df['flowStart'].dt.second\n",
        "df['flowStart_minute'] = df['flowStart'].dt.minute\n",
        "df['flowStart_hour'] = df['flowStart'].dt.hour\n",
        "df['flowStart_day_of_week'] = df['flowStart'].dt.weekday\n",
        "\n",
        "df['flowEnd_second'] = df['flowEnd'].dt.second\n",
        "df['flowEnd_minute'] = df['flowEnd'].dt.minute\n",
        "df['flowEnd_hour'] = df['flowEnd'].dt.hour\n",
        "df['flowEnd_day_of_week'] = df['flowEnd'].dt.weekday\n",
        "\n",
        "df['flowDuration_hours'] = (df['flowDuration'] // 3600)\n",
        "df['flowDuration_minutes'] = (df['flowDuration'] % 3600) // 60\n",
        "df['flowDuration_seconds'] = df['flowDuration'] % 60\n",
        "\n",
        "def label_traffic(df):\n",
        "    # Define normal thresholds\n",
        "    normal_protocols = [6, 17, 1]  # TCP and UDP\n",
        "    normal_port_range = set(range(0, 49152))\n",
        "    normal_pkt_count_max = 2000\n",
        "    normal_octet_count_max = 1000000\n",
        "    normal_packet_size_range = range(20, 1500)\n",
        "    normal_flow_duration_range = range(50, 3600000)  # 50 ms to 1 hour\n",
        "    normal_piat_range = range(0, 10000)  # 0 to 10 seconds\n",
        "\n",
        "    # Initialize the traffic_label column\n",
        "    df['traffic_label'] = 'normal'\n",
        "\n",
        "    # Vectorized conditions\n",
        "    df.loc[~df['proto'].isin(normal_protocols) | df['proto'].isna(), 'traffic_label'] = 'malicious'\n",
        "\n",
        "    df.loc[df['flowEndReason'] == 1, 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['src_port'].isin(normal_port_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['dst_port'].isin(normal_port_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['pktTotalCount'] > normal_pkt_count_max, 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['octetTotalCount'] > normal_octet_count_max, 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['min_ps'].between(20, 1500), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['max_ps'].between(20, 1500), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['avg_ps'].between(20, 1500), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_ps'].between(20, 1500), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['flowDuration'].between(50, 3600000), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['min_piat'].between(0, 10000), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['max_piat'].between(0, 10000), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['avg_piat'].between(0, 10000), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_piat'].between(0, 10000), 'traffic_label'] = 'malicious'\n",
        "    df.loc[(df['flowStart'] < pd.Timestamp('1970-01-01')) | (df['flowStart'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[(df['flowEnd'] < pd.Timestamp('1970-01-01')) | (df['flowEnd'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['flowEnd'] < df['flowStart'], 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # Process forward and backward flow features\n",
        "    for prefix in ['f_', 'b_']:\n",
        "        df.loc[df[prefix + 'pktTotalCount'] > normal_pkt_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[df[prefix + 'octetTotalCount'] > normal_octet_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'min_ps'].between(20, 1500), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'max_ps'].between(20, 1500), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_ps'].between(20, 1500), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_ps'].between(20, 1500), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'flowDuration'].between(50, 3600000), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'min_piat'].between(0, 10000), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'max_piat'].between(0, 10000), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_piat'].between(0, 10000), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_piat'].between(0, 10000), 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # IP Address checks\n",
        "    normal_src_ip_ranges = ['192.168.', '10.', '172.16.', '172.17.', '172.18.', '172.19.', '172.20.', '172.21.', '172.22.', '172.23.', '172.24.', '172.25.', '172.26.', '172.27.', '172.28.', '172.29.', '172.30.', '172.31.']\n",
        "    df['src_ip'] = df['src_ip'].astype(str)  # Ensure src_ip column is treated as strings\n",
        "    df['dst_ip'] = df['dst_ip'].astype(str)  # Ensure dst_ip column is treated as strings\n",
        "    df.loc[df['src_ip'].apply(lambda ip: any(ip.startswith(range) for range in normal_src_ip_ranges)), 'traffic_label'] = 'normal'\n",
        "    df.loc[df['dst_ip'].apply(lambda ip: any(ip.startswith(range) for range in normal_src_ip_ranges)), 'traffic_label'] = 'normal'\n",
        "\n",
        "    # Web service, application protocol, and category checks\n",
        "    normal_web_services = ['Google', 'Microsoft', 'HTTP', 'DNS', 'Amazon', 'MSN', 'TLS', 'Yahoo', 'DHCP', 'WindowsUpdate', 'NetBIOS', 'RX', 'MS_OneDrive', 'GMail', 'Dropbox', 'GoogleServices', 'ICMP']\n",
        "    normal_application_protocols = ['HTTP', 'TLS', 'DNS', 'QUIC', 'IMAPS', 'STUN', 'SMTPS', 'POPS', 'Skype', 'SMBv23', 'NetBIOS', 'RDP', 'ApplePush', 'MQTT']\n",
        "    normal_categories = ['Network', 'Web', 'SoftwareUpdate', 'RPC', 'System', 'Cloud', 'Mail', 'FTP', 'Mining', 'VPN', 'RemoteAccess']\n",
        "    df.loc[~df['web_service'].isin(normal_web_services), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['application_protocol'].isin(normal_application_protocols), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['category'].isin(normal_categories), 'traffic_label'] = 'malicious'\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply the labeling function to the DataFrame\n",
        "df = label_traffic(df)\n",
        "record_time(\"Labeling Function Applied\", overall_start_time)\n",
        "\n",
        "# Encoding categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['category_encoded'] = label_encoder.fit_transform(df['traffic_label'])\n",
        "record_time(\"Categorical Labels Encoded\", overall_start_time)\n",
        "\n",
        "# Feature selection and splitting data\n",
        "X = df.drop(columns=['traffic_label', 'category_encoded'])\n",
        "y = df['category_encoded']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "record_time(\"Data Split into Train and Test Sets\", overall_start_time)\n",
        "\n",
        "# Filter out non-numeric columns\n",
        "numeric_columns = X_train.select_dtypes(include=[np.number]).columns\n",
        "X_train_numeric = X_train[numeric_columns]\n",
        "X_test_numeric = X_test[numeric_columns]\n",
        "\n",
        "# Handle missing values and scale data for numeric columns only\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(X_train_numeric)\n",
        "X_test_imputed = imputer.transform(X_test_numeric)\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "record_time(\"Preprocessing Applied\", overall_start_time)\n",
        "\n",
        "# Define and fit classifiers\n",
        "lr_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "rf_clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "ab_clf = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
        "gb_clf = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "\n",
        "lr_clf.fit(X_train_scaled, y_train)\n",
        "rf_clf.fit(X_train_scaled, y_train)\n",
        "ab_clf.fit(X_train_scaled, y_train)\n",
        "gb_clf.fit(X_train_scaled, y_train)\n",
        "record_time(\"Classifiers Fitted\", overall_start_time)\n",
        "\n",
        "# Evaluate models and plot confusion matrices and ROC curves\n",
        "for clf, name in [(lr_clf, 'Logistic Regression'), (rf_clf, 'Random Forest'), (ab_clf, 'AdaBoost'), (gb_clf, 'Gradient Boosting')]:\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "    y_pred_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plot_confusion_matrix(cm, name)\n",
        "    plot_roc_curve(y_test, y_pred_proba, name)\n",
        "\n",
        "# Calculate accuracy and F1-score for each model\n",
        "lr_accuracy, lr_f1 = accuracy_score(y_test, lr_clf.predict(X_test_scaled)), f1_score(y_test, lr_clf.predict(X_test_scaled))\n",
        "rf_accuracy, rf_f1 = accuracy_score(y_test, rf_clf.predict(X_test_scaled)), f1_score(y_test, rf_clf.predict(X_test_scaled))\n",
        "ab_accuracy, ab_f1 = accuracy_score(y_test, ab_clf.predict(X_test_scaled)), f1_score(y_test, ab_clf.predict(X_test_scaled))\n",
        "gb_accuracy, gb_f1 = accuracy_score(y_test, gb_clf.predict(X_test_scaled)), f1_score(y_test, gb_clf.predict(X_test_scaled))\n",
        "\n",
        "# Print the results\n",
        "print(\"\\nLogistic Regression Classifier:\\nAccuracy:\", lr_accuracy, \"\\nF1-Score:\", lr_f1)\n",
        "print(\"\\nRandom Forest Classifier:\\nAccuracy:\", rf_accuracy, \"\\nF1-Score:\", rf_f1)\n",
        "print(\"\\nAdaBoost Classifier:\\nAccuracy:\", ab_accuracy, \"\\nF1-Score:\", ab_f1)\n",
        "print(\"\\nGradient Boosting Classifier:\\nAccuracy:\", gb_accuracy, \"\\nF1-Score:\", gb_f1)\n",
        "print(\"\\nProcess Completed - Time:\", datetime.datetime.now() - overall_start_time)\n",
        "\n"
      ],
      "metadata": {
        "id": "4DlN0MaY8i1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['proto'].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX7gUzGFVA_8",
        "outputId": "d32f3fe3-2440-4f3c-8e39-988e50255239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17.  1.  6. nan]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[['flowStart', 'flowEnd', 'flowDuration']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cva-48EYBfHE",
        "outputId": "44b062a3-7804-41e8-bbf3-f558ede7219e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            flowStart             flowEnd  flowDuration\n",
            "0 2019-04-22 17:18:51 2019-04-22 17:47:13   1701.385427\n",
            "1 2019-04-22 17:18:51 2019-04-22 17:47:13   1701.385515\n",
            "2 2019-04-22 20:06:14 2019-04-22 20:30:25   1450.967340\n",
            "3 2019-04-22 20:06:14 2019-04-22 20:30:25   1450.967130\n",
            "4 2019-04-22 20:54:59 2019-04-22 20:54:59      0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the count of instances in each class after labeling\n",
        "label_counts = df['traffic_label'].value_counts()\n",
        "print(\"Label distribution after labeling:\")\n",
        "print(label_counts)\n",
        "\n",
        "print(df['category_encoded'].value_counts())\n",
        "\n",
        "print (\" \\n \")\n",
        "print(df['traffic_label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u9PdKkaQL3_",
        "outputId": "f557c09e-482a-4233-f305-dd3285d8eba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label distribution after labeling:\n",
            "malicious    9958\n",
            "normal         42\n",
            "Name: traffic_label, dtype: int64\n",
            "0    9958\n",
            "1      42\n",
            "Name: category_encoded, dtype: int64\n",
            " \n",
            " \n",
            "malicious    9958\n",
            "normal         42\n",
            "Name: traffic_label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before Labeling:\")\n",
        "print(df['traffic_label'].value_counts())\n",
        "\n",
        "# Apply the labeling function to the DataFrame\n",
        "df = label_traffic(df)\n",
        "record_time(\"Labeling Function Applied\", overall_start_time)\n",
        "\n",
        "print(\"After Labeling:\")\n",
        "print(df['traffic_label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0prDm8zUUmlb",
        "outputId": "48ade1cb-b073-414f-f69b-7ba994f286e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Labeling:\n",
            "malicious    8054\n",
            "normal       1946\n",
            "Name: traffic_label, dtype: int64\n",
            "Labeling Function Applied - Time Elapsed: 0:01:42.241708\n",
            "After Labeling:\n",
            "malicious    8054\n",
            "normal       1946\n",
            "Name: traffic_label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lengths of unique values arrays\n",
        "web_services_length = len(unique_web_services)\n",
        "application_protocols_length = len(unique_application_protocols)\n",
        "categories_length = len(unique_categories)\n",
        "\n",
        "# Print the lengths\n",
        "print(\"Length of Unique Web Services:\", web_services_length)\n",
        "print(\"Length of Unique Application Protocols:\", application_protocols_length)\n",
        "print(\"Length of Unique Categories:\", categories_length)\n",
        "# Get unique values in the 'web_service' column\n",
        "unique_web_services = df['web_service'].unique()\n",
        "\n",
        "# Get unique values in the 'application_protocol' column\n",
        "unique_application_protocols = df['application_protocol'].unique()\n",
        "\n",
        "# Get unique values in the 'category' column\n",
        "unique_categories = df['category'].unique()\n",
        "\n",
        "# Print the unique values\n",
        "print(\"Unique Web Services:\")\n",
        "print(unique_web_services)\n",
        "\n",
        "print(\"\\nUnique Application Protocols:\")\n",
        "print(unique_application_protocols)\n",
        "\n",
        "print(\"\\nUnique Categories:\")\n",
        "print(unique_categories)\n",
        "# Existing normal lists\n",
        "normal_web_services = ['Google', 'Microsoft', 'HTTP', 'DNS', 'Amazon', 'MSN', 'TLS', 'Yahoo', 'DHCP', 'WindowsUpdate', 'NetBIOS', 'RX', 'MS_OneDrive', 'GMail', 'Dropbox', 'GoogleServices', 'ICMP', 'UbuntuONE', 'GoogleDrive', 'YouTube', 'HTTP_Proxy', 'NTP', 'Apple', 'AppleiTunes', 'AppleStore', 'ApplePush', 'AppleiCloud', 'IMAPS', 'IMO', 'Office365', 'Skype', 'Cloudflare']\n",
        "normal_application_protocols = ['HTTP', 'TLS', 'DNS', 'QUIC', 'IMAPS', 'STUN', 'SMTPS', 'POPS', 'Skype', 'SMBv23', 'NetBIOS', 'RDP', 'ApplePush', 'MQTT']\n",
        "\n",
        "normal_categories = ['Network', 'Web', 'SoftwareUpdate', 'RPC', 'System', 'Cloud', 'Mail', 'FTP', 'Mining', 'VPN', 'RemoteAccess', 'Email', 'Media', 'Streaming', 'VoIP', 'Collaborative']\n",
        "\n",
        "# Add missing values from Unique Web Services\n",
        "for service in unique_web_services:\n",
        "    if service not in normal_web_services and pd.notna(service):\n",
        "        normal_web_services.append(service)\n",
        "\n",
        "# Add missing values from Unique Application Protocols\n",
        "for protocol in unique_application_protocols:\n",
        "    if protocol not in normal_application_protocols and pd.notna(protocol):\n",
        "        normal_application_protocols.append(protocol)\n",
        "\n",
        "# Add missing values from Unique Categories\n",
        "for category in unique_categories:\n",
        "    if category not in normal_categories and pd.notna(category):\n",
        "        normal_categories.append(category)\n",
        "\n",
        "# Print the updated normal lists\n",
        "print(\"Updated Normal Web Services:\")\n",
        "print(normal_web_services)\n",
        "\n",
        "print(\"\\nUpdated Normal Application Protocols:\")\n",
        "print(normal_application_protocols)\n",
        "\n",
        "print(\"\\nUpdated Normal Categories:\")\n",
        "print(normal_categories)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x_HtOmyRjrl",
        "outputId": "e0029426-af48-4417-b555-98ac66484ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of Unique Web Services: 34\n",
            "Length of Unique Application Protocols: 7\n",
            "Length of Unique Categories: 13\n",
            "Unique Web Services:\n",
            "['DHCP' 'ICMP' 'HTTP' 'Microsoft' 'WindowsUpdate' 'Unknown' 'DNS' 'RX'\n",
            " 'TLS' 'NetBIOS' 'GoogleServices' 'Amazon' 'MSN' 'Yahoo' 'MS_OneDrive'\n",
            " 'Google' 'Dropbox' 'GMail' 'UbuntuONE' 'GoogleDrive' 'YouTube'\n",
            " 'HTTP_Proxy' 'NTP' 'Apple' 'AppleiTunes' 'AppleStore' 'ApplePush'\n",
            " 'AppleiCloud' 'IMAPS' 'IMO' 'Office365' 'Skype' 'Cloudflare' nan]\n",
            "\n",
            "Unique Application Protocols:\n",
            "['Unknown' 'HTTP' 'TLS' 'DNS' 'QUIC' 'IMAPS' nan]\n",
            "\n",
            "Unique Categories:\n",
            "['Network' 'Web' 'SoftwareUpdate' 'Unspecified' 'RPC' 'System' 'Cloud'\n",
            " 'Email' 'Media' 'Streaming' 'VoIP' 'Collaborative' nan]\n",
            "Updated Normal Web Services:\n",
            "['Google', 'Microsoft', 'HTTP', 'DNS', 'Amazon', 'MSN', 'TLS', 'Yahoo', 'DHCP', 'WindowsUpdate', 'NetBIOS', 'RX', 'MS_OneDrive', 'GMail', 'Dropbox', 'GoogleServices', 'ICMP', 'UbuntuONE', 'GoogleDrive', 'YouTube', 'HTTP_Proxy', 'NTP', 'Apple', 'AppleiTunes', 'AppleStore', 'ApplePush', 'AppleiCloud', 'IMAPS', 'IMO', 'Office365', 'Skype', 'Cloudflare', 'Unknown']\n",
            "\n",
            "Updated Normal Application Protocols:\n",
            "['HTTP', 'TLS', 'DNS', 'QUIC', 'IMAPS', 'STUN', 'SMTPS', 'POPS', 'Skype', 'SMBv23', 'NetBIOS', 'RDP', 'ApplePush', 'MQTT', 'Unknown']\n",
            "\n",
            "Updated Normal Categories:\n",
            "['Network', 'Web', 'SoftwareUpdate', 'RPC', 'System', 'Cloud', 'Mail', 'FTP', 'Mining', 'VPN', 'RemoteAccess', 'Email', 'Media', 'Streaming', 'VoIP', 'Collaborative', 'Unspecified']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X7ocOYc3ca5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Function to record the current time since the overall start\n",
        "def record_time(step_name, overall_start_time):\n",
        "    print(f\"{step_name} - Time Elapsed: {datetime.datetime.now() - overall_start_time}\")\n",
        "\n",
        "# Start the overall timer\n",
        "overall_start_time = datetime.datetime.now()\n",
        "record_time(\"Dataset Loaded\", overall_start_time)\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(cm, classifier_name):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix for {classifier_name}')\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "\n",
        "# Function to plot ROC curve\n",
        "def plot_roc_curve(y_true, y_scores, classifier_name):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve for {classifier_name}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('Unicauca-dataset-April-June-2019-Network-flows-50000rows(ALLFEATURES).csv')\n",
        "overall_start_time = datetime.datetime.now()\n",
        "record_time(\"Dataset Loaded\", overall_start_time)\n",
        "\n",
        "# Convert Unix timestamps to datetime objects\n",
        "df['flowStart'] = pd.to_datetime(df['flowStart'], unit='s')\n",
        "df['flowEnd'] = pd.to_datetime(df['flowEnd'], unit='s')\n",
        "max_timestamp = pd.to_datetime('now')  # Define max_timestamp\n",
        "\n",
        "# Extracting temporal features\n",
        "df['flowStart_second'] = df['flowStart'].dt.second\n",
        "df['flowStart_minute'] = df['flowStart'].dt.minute\n",
        "df['flowStart_hour'] = df['flowStart'].dt.hour\n",
        "df['flowStart_day_of_week'] = df['flowStart'].dt.weekday\n",
        "\n",
        "df['flowEnd_second'] = df['flowEnd'].dt.second\n",
        "df['flowEnd_minute'] = df['flowEnd'].dt.minute\n",
        "df['flowEnd_hour'] = df['flowEnd'].dt.hour\n",
        "df['flowEnd_day_of_week'] = df['flowEnd'].dt.weekday\n",
        "\n",
        "df['flowDuration_hours'] = (df['flowDuration'] // 3600)\n",
        "df['flowDuration_minutes'] = (df['flowDuration'] % 3600) // 60\n",
        "df['flowDuration_seconds'] = df['flowDuration'] % 60\n",
        "\n",
        "print(\"Number of rows before labeling:\", len(df))\n",
        "\n",
        "\n",
        "def label_traffic_advanced(df):\n",
        "    df['traffic_label'] = 'normal'\n",
        "\n",
        "    # Feature Engineering\n",
        "    df['src_dst_port_diff'] = abs(df['src_port'] - df['dst_port'])\n",
        "    df['flow_duration_log'] = np.log(df['flowDuration'] + 1)\n",
        "    df['high_octet_per_packet'] = df['octetTotalCount'] / (df['pktTotalCount'] + 1)\n",
        "\n",
        "    # Define suspicious criteria\n",
        "    # (These thresholds should be adjusted based on your network data analysis)\n",
        "    suspicious_ports = set(range(49152, 65536))  # Dynamic/private ports\n",
        "    pkt_count_threshold = 15000  # Increased threshold\n",
        "    data_volume_threshold = 2*10**7  # Increased threshold\n",
        "    short_flow_duration_threshold = 500  # in ms\n",
        "    long_flow_duration_threshold = 3600000  # 1 hour\n",
        "    unusual_packet_size_threshold = 1500  # Ethernet MTU size\n",
        "    high_port_diff_threshold = 10000  # Large difference between src and dst ports\n",
        "    high_octet_per_packet_threshold = 1500  # Abnormal octet-to-packet ratio\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        # Conditions based on raw and engineered features\n",
        "        if (\n",
        "            row['src_port'] in suspicious_ports or\n",
        "            row['dst_port'] in suspicious_ports or\n",
        "            row['pktTotalCount'] > pkt_count_threshold or\n",
        "            row['octetTotalCount'] > data_volume_threshold\n",
        "            row['flowDuration'] < short_flow_duration_threshold or\n",
        "            row['flowDuration'] > long_flow_duration_threshold or\n",
        "            row['max_ps'] > unusual_packet_size_threshold or\n",
        "            row['min_ps'] > unusual_packet_size_threshold or\n",
        "            row['src_dst_port_diff'] > high_port_diff_threshold or\n",
        "            row['high_octet_per_packet'] > high_octet_per_packet_threshold\n",
        "        ):\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # Drop engineered features if they are not needed for further analysis\n",
        "    df.drop(['src_dst_port_diff', 'flow_duration_log', 'high_octet_per_packet'], axis=1, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply the advanced labeling function\n",
        "df = label_traffic_advanced(df)\n",
        "print(\"Label distribution after advanced labeling:\")\n",
        "print(df['traffic_label'].value_counts())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Apply the labeling function to the DataFrame\n",
        "df = label_traffic(df)\n",
        "record_time(\"Labeling Function Applied\", overall_start_time)\n",
        "\n",
        "# Apply the labeling function\n",
        "print(\"Number of rows after labeling:\", len(df))\n",
        "\n",
        "# Encoding categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['category_encoded'] = label_encoder.fit_transform(df['traffic_label'])\n",
        "record_time(\"Categorical Labels Encoded\", overall_start_time)\n",
        "\n",
        "# Feature selection and splitting data\n",
        "X = df.drop(columns=['traffic_label', 'category_encoded'])\n",
        "y = df['category_encoded']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "record_time(\"Data Split into Train and Test Sets\", overall_start_time)\n",
        "\n",
        "# Filter out non-numeric columns\n",
        "numeric_columns = X_train.select_dtypes(include=[np.number]).columns\n",
        "X_train_numeric = X_train[numeric_columns]\n",
        "X_test_numeric = X_test[numeric_columns]\n",
        "\n",
        "# Handle missing values and scale data for numeric columns only\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(X_train_numeric)\n",
        "X_test_imputed = imputer.transform(X_test_numeric)\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "record_time(\"Preprocessing Applied\", overall_start_time)\n",
        "\n",
        "# Define and fit classifiers\n",
        "lr_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "rf_clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "ab_clf = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
        "gb_clf = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "lr_clf.fit(X_train_scaled, y_train)\n",
        "rf_clf.fit(X_train_scaled, y_train)\n",
        "ab_clf.fit(X_train_scaled, y_train)\n",
        "gb_clf.fit(X_train_scaled, y_train)\n",
        "record_time(\"Classifiers Fitted\", overall_start_time)\n",
        "\n",
        "# Evaluate models and plot confusion matrices and ROC curves\n",
        "for clf, name in [(lr_clf, 'Logistic Regression'), (rf_clf, 'Random Forest'), (ab_clf, 'AdaBoost'), (gb_clf, 'Gradient Boosting')]:\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "    y_pred_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plot_confusion_matrix(cm, name)\n",
        "    plot_roc_curve(y_test, y_pred_proba, name)\n",
        "\n",
        "# Calculate accuracy and F1-score for each model\n",
        "lr_accuracy, lr_f1 = accuracy_score(y_test, lr_clf.predict(X_test_scaled)), f1_score(y_test, lr_clf.predict(X_test_scaled))\n",
        "rf_accuracy, rf_f1 = accuracy_score(y_test, rf_clf.predict(X_test_scaled)), f1_score(y_test, rf_clf.predict(X_test_scaled))\n",
        "ab_accuracy, ab_f1 = accuracy_score(y_test, ab_clf.predict(X_test_scaled)), f1_score(y_test, ab_clf.predict(X_test_scaled))\n",
        "gb_accuracy, gb_f1 = accuracy_score(y_test, gb_clf.predict(X_test_scaled)), f1_score(y_test, gb_clf.predict(X_test_scaled))\n",
        "\n",
        "# Print the results\n",
        "print(\"\\nLogistic Regression Classifier:\\nAccuracy:\", lr_accuracy, \"\\nF1-Score:\", lr_f1)\n",
        "print(\"\\nRandom Forest Classifier:\\nAccuracy:\", rf_accuracy, \"\\nF1-Score:\", rf_f1)\n",
        "print(\"\\nAdaBoost Classifier:\\nAccuracy:\", ab_accuracy, \"\\nF1-Score:\", ab_f1)\n",
        "print(\"\\nGradient Boosting Classifier:\\nAccuracy:\", gb_accuracy, \"\\nF1-Score:\", gb_f1)\n",
        "print(\"\\nProcess Completed - Time:\", datetime.datetime.now() - overall_start_time)\n",
        "print(\"Before Labeling:\")\n",
        "print(df['traffic_label'].value_counts())\n",
        "\n",
        "# Apply the labeling function to the DataFrame\n",
        "df = label_traffic(df)\n",
        "record_time(\"Labeling Function Applied\", overall_start_time)\n",
        "\n",
        "print(\"After Labeling:\")\n",
        "print(df['traffic_label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "dcGFG_5-XTMP",
        "outputId": "1f48de6c-def2-424a-b9fb-69e88a692bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (<ipython-input-114-73480fa20b20>, line 93)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/compilerop.py\u001b[0m in \u001b[0;36mast_parse\u001b[0;34m(self, source, filename, symbol)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mArguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mexactly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         and are passed to the built-in compile function.\"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mPyCF_ONLY_AST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_compiler_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSyntaxError\u001b[0m: invalid syntax. Perhaps you forgot a comma? (<ipython-input-114-73480fa20b20>, line 93)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before Labeling:\")\n",
        "print(df['label_network_traffic'].value_counts())\n",
        "\n",
        "# Apply the labeling function to the DataFrame\n",
        "df = label_network_traffic(df)\n",
        "record_time(\"Labeling Function Applied\", overall_start_time)\n",
        "\n",
        "print(\"After Labeling:\")\n",
        "print(df['label_network_traffic'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "62jgzUNqXcMw",
        "outputId": "264621ab-6bca-4fae-faca-54145c749852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Labeling:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'label_network_traffic'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label_network_traffic'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-e2ae0f186950>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Before Labeling:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_network_traffic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Apply the labeling function to the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_network_traffic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label_network_traffic'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = label_network_traffic(df)\n",
        "print(\"Label distribution after labeling:\")\n",
        "print(df['label_network_traffic'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "b58cAeEgdH5J",
        "outputId": "a8db82eb-0385-4608-bdae-a8fa61eaa1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label distribution after labeling:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'label_network_traffic'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label_network_traffic'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-ccda104b4b99>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_network_traffic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Label distribution after labeling:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_network_traffic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label_network_traffic'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label_traffic_simple(df):\n",
        "    df['traffic_label'] = 'normal'\n",
        "    malicious_protocols = [6, 17, 1]  # TCP, UDP, ICMP\n",
        "    for index, row in df.iterrows():\n",
        "        if row['proto'] not in malicious_protocols:\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "    return df\n",
        "\n",
        "df = label_traffic_simple(df)\n",
        "print(\"Label distribution after simple labeling:\")\n",
        "print(df['traffic_label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU4UqT-EdaN3",
        "outputId": "0d88361b-f4b9-4b74-e8ea-2d59efe50bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label distribution after simple labeling:\n",
            "normal    10000\n",
            "Name: traffic_label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique protocols in the dataset:\")\n",
        "print(df['proto'].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M34F6Hfgdlwm",
        "outputId": "6b3a7b9e-7eaa-4b4c-e069-5bf2c1b41e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique protocols in the dataset:\n",
            "[17  1  6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "0568jQQhmIw2",
        "outputId": "9c884b03-4f7f-4e07-917a-2d7ea89e6860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-073f0588-674d-4670-9a3a-6c7a89cf8200\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-073f0588-674d-4670-9a3a-6c7a89cf8200\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Unicauca-dataset-April-June-2019-Network-flows-50000rows(ALLFEATURES).csv to Unicauca-dataset-April-June-2019-Network-flows-50000rows(ALLFEATURES).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Function to record the current time since the overall start\n",
        "def record_time(step_name, overall_start_time):\n",
        "    print(f\"{step_name} - Time Elapsed: {datetime.datetime.now() - overall_start_time}\")\n",
        "\n",
        "# Function to label network traffic\n",
        "def label_network_traffic(df):\n",
        "    df['traffic_label'] = 'normal'\n",
        "\n",
        "    # Feature Engineering (if needed)\n",
        "    df['src_dst_port_diff'] = abs(df['src_port'] - df['dst_port'])\n",
        "    df['flow_duration_log'] = np.log(df['flowDuration'] + 1)\n",
        "    df['high_octet_per_packet'] = df['octetTotalCount'] / (df['pktTotalCount'] + 1)\n",
        "\n",
        "    # Adjusting thresholds to be less strict\n",
        "    suspicious_ports = set(range(60000, 65536))  # Dynamic/private ports\n",
        "    pkt_count_threshold = 150000  # Increased threshold for packet count\n",
        "    data_volume_threshold = 2*10**7  # Increased threshold for data volume\n",
        "    short_duration_threshold = 1000  # Increased threshold for short flow duration\n",
        "    long_duration_threshold = 7200000  # Increased threshold for long flow duration (2 hours)\n",
        "    unusual_packet_size_threshold = 20000  # Increased threshold for packet size\n",
        "    high_port_diff_threshold = 20000  # Increased threshold for port difference\n",
        "    high_octet_per_packet_threshold = 20000  # Increased threshold for octet-to-packet ratio\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        if (\n",
        "            row['src_port'] in suspicious_ports or\n",
        "            row['dst_port'] in suspicious_ports or\n",
        "            row['pktTotalCount'] > pkt_count_threshold or\n",
        "            row['octetTotalCount'] > data_volume_threshold or\n",
        "#            row['flowDuration'] < short_duration_threshold or\n",
        "            row['flowDuration'] > long_duration_threshold or\n",
        "            row['max_ps'] > unusual_packet_size_threshold or\n",
        "            row['min_ps'] > unusual_packet_size_threshold or\n",
        "#            row['src_dst_port_diff'] > high_port_diff_threshold or\n",
        "            row['high_octet_per_packet'] > high_octet_per_packet_threshold\n",
        "        ):\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # Clean up the DataFrame by removing engineered features\n",
        "    df.drop(['src_dst_port_diff', 'flow_duration_log', 'high_octet_per_packet'], axis=1, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('Unicauca-dataset-April-June-2019-Network-flows-10000rows(ALLFEATURES).csv')\n",
        "overall_start_time = datetime.datetime.now()\n",
        "record_time(\"Dataset Loaded\", overall_start_time)\n",
        "\n",
        "# Apply the labeling function\n",
        "df = label_network_traffic(df)\n",
        "record_time(\"Labeling Function Applied\", overall_start_time)\n",
        "# Display the unique classes in the dataset\n",
        "unique_classes = df['traffic_label'].unique()\n",
        "print(\"Unique classes in the dataset:\", unique_classes)\n",
        "\n",
        "\n",
        "# Encoding categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['category_encoded'] = label_encoder.fit_transform(df['traffic_label'])\n",
        "record_time(\"Categorical Labels Encoded\", overall_start_time)\n",
        "\n",
        "# Feature selection and splitting data\n",
        "X = df.drop(columns=['traffic_label', 'category_encoded'])\n",
        "y = df['category_encoded']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "record_time(\"Data Split into Train and Test Sets\", overall_start_time)\n",
        "\n",
        "# Preprocessing: Handle missing values and scale data\n",
        "numeric_columns = X_train.select_dtypes(include=[np.number]).columns\n",
        "X_train_numeric = X_train[numeric_columns]\n",
        "X_test_numeric = X_test[numeric_columns]\n",
        "\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Apply imputation and scaling only to numeric data\n",
        "X_train_imputed = imputer.fit_transform(X_train_numeric)\n",
        "X_test_imputed = imputer.transform(X_test_numeric)\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "record_time(\"Preprocessing Applied\", overall_start_time)\n",
        "\n",
        "# Define and fit classifiers\n",
        "classifiers = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=50, random_state=42),\n",
        "    'AdaBoost': AdaBoostClassifier(n_estimators=50, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "}\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_train_scaled, y_train)\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print(f\"{name} - Accuracy: {accuracy}, F1 Score: {f1}\")\n",
        "    # Additional evaluation metrics can be added here\n",
        "\n",
        "print(\"\\nProcess Completed - Time:\", datetime.datetime.now() - overall_start_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAV9fMZ4iSiY",
        "outputId": "9283ee2a-bc6c-4b78-f8b9-848fb599dec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded - Time Elapsed: 0:00:00.000053\n",
            "Labeling Function Applied - Time Elapsed: 0:00:00.702583\n",
            "Unique classes in the dataset: ['normal' 'malicious']\n",
            "Categorical Labels Encoded - Time Elapsed: 0:00:00.708464\n",
            "Data Split into Train and Test Sets - Time Elapsed: 0:00:00.722498\n",
            "Preprocessing Applied - Time Elapsed: 0:00:00.781671\n",
            "Logistic Regression - Accuracy: 0.992, F1 Score: 0.9949685534591195\n",
            "Random Forest - Accuracy: 0.9995, F1 Score: 0.9996852376455775\n",
            "AdaBoost - Accuracy: 0.9995, F1 Score: 0.9996852376455775\n",
            "Gradient Boosting - Accuracy: 0.9995, F1 Score: 0.9996852376455775\n",
            "\n",
            "Process Completed - Time: 0:00:04.531931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the count of instances in each class after labeling\n",
        "label_counts = df['traffic_label'].value_counts()\n",
        "print(\"Label distribution after labeling:\")\n",
        "print(label_counts)\n",
        "\n",
        "print(df['category_encoded'].value_counts())\n",
        "\n",
        "print (\" \\n \")\n",
        "print(df['traffic_label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsKxXzRjkar8",
        "outputId": "29f96c71-1555-46a8-ecd3-72dbbcd8ec25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label distribution after labeling:\n",
            "normal       7939\n",
            "malicious    2061\n",
            "Name: traffic_label, dtype: int64\n",
            "1    7939\n",
            "0    2061\n",
            "Name: category_encoded, dtype: int64\n",
            " \n",
            " \n",
            "normal       7939\n",
            "malicious    2061\n",
            "Name: traffic_label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Function to record the current time since the overall start\n",
        "def record_time(step_name, overall_start_time):\n",
        "    print(f\"{step_name} - Time Elapsed: {datetime.datetime.now() - overall_start_time}\")\n",
        "\n",
        "# Function to label network traffic\n",
        "def label_network_traffic_updated(df):\n",
        "    df['traffic_label'] = 'normal'\n",
        "\n",
        "    # Define thresholds and suspicious indicators\n",
        "    suspicious_ports = set(range(49152, 65536))  # Dynamic/private ports\n",
        "    high_pkt_count_threshold = 5000\n",
        "    high_data_volume_threshold = 5*10**6\n",
        "    short_duration_threshold = 500  # Very short flows in milliseconds\n",
        "    long_duration_threshold = 3600000  # 1 hour\n",
        "    large_packet_size_threshold = 1500  # Larger than typical MTU size\n",
        "\n",
        "    # Lists of services, protocols, and categories that might be suspicious\n",
        "    suspicious_web_services = ['Unknown']\n",
        "    suspicious_protocols = ['Unknown']\n",
        "    suspicious_categories = ['Mining', 'RemoteAccess', 'Unspecified']\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        # Combination of conditions for sophisticated detection\n",
        "        if (\n",
        "            (row['src_port'] in suspicious_ports or row['dst_port'] in suspicious_ports) or\n",
        "            (row['pktTotalCount'] > high_pkt_count_threshold) or\n",
        "            (row['octetTotalCount'] > high_data_volume_threshold) or\n",
        "            (row['flowDuration'] < short_duration_threshold or row['flowDuration'] > long_duration_threshold) or\n",
        "            (max(row['max_ps'], row['min_ps']) > large_packet_size_threshold) or\n",
        "            (row['web_service'] in suspicious_web_services or row['application_protocol'] in suspicious_protocols or row['category'] in suspicious_categories) or\n",
        "            (row['category'] == 'Network' and row['src_prefix'] != 'local' and row['dst_prefix'] != 'local') or\n",
        "            (row['category'] == 'VPN' and row['src_prefix'] != 'local' and row['dst_prefix'] != 'local') or\n",
        "            (row['category'] == 'RemoteAccess' and row['src_prefix'] != 'local' and row['dst_prefix'] != 'local')\n",
        "        ):\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('Unicauca-dataset-April-June-2019-Network-flows-50000rows(ALLFEATURES).csv')\n",
        "overall_start_time = datetime.datetime.now()\n",
        "record_time(\"Dataset Loaded\", overall_start_time)\n",
        "\n",
        "# Apply the labeling function\n",
        "df = label_network_traffic(df)\n",
        "record_time(\"Labeling Function Applied\", overall_start_time)\n",
        "# Display the unique classes in the dataset\n",
        "unique_classes = df['traffic_label'].unique()\n",
        "print(\"Unique classes in the dataset:\", unique_classes)\n",
        "\n",
        "\n",
        "# Encoding categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['category_encoded'] = label_encoder.fit_transform(df['traffic_label'])\n",
        "record_time(\"Categorical Labels Encoded\", overall_start_time)\n",
        "\n",
        "# Feature selection and splitting data\n",
        "X = df.drop(columns=['traffic_label', 'category_encoded'])\n",
        "y = df['category_encoded']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "record_time(\"Data Split into Train and Test Sets\", overall_start_time)\n",
        "\n",
        "# Preprocessing: Handle missing values and scale data\n",
        "numeric_columns = X_train.select_dtypes(include=[np.number]).columns\n",
        "X_train_numeric = X_train[numeric_columns]\n",
        "X_test_numeric = X_test[numeric_columns]\n",
        "\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Apply imputation and scaling only to numeric data\n",
        "X_train_imputed = imputer.fit_transform(X_train_numeric)\n",
        "X_test_imputed = imputer.transform(X_test_numeric)\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "record_time(\"Preprocessing Applied\", overall_start_time)\n",
        "\n",
        "# Define and fit classifiers\n",
        "classifiers = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=50, random_state=42),\n",
        "    'AdaBoost': AdaBoostClassifier(n_estimators=50, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "}\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_train_scaled, y_train)\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print(f\"{name} - Accuracy: {accuracy}, F1 Score: {f1}\")\n",
        "    # Additional evaluation metrics can be added here\n",
        "\n",
        "print(\"\\nProcess Completed - Time:\", datetime.datetime.now() - overall_start_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xh47bmfytZ_D",
        "outputId": "3681b408-5105-4099-a8b6-fb6ac3e4489c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded - Time Elapsed: 0:00:00.000081\n",
            "Labeling Function Applied - Time Elapsed: 0:00:01.105822\n",
            "Unique classes in the dataset: ['normal' 'malicious']\n",
            "Categorical Labels Encoded - Time Elapsed: 0:00:01.116025\n",
            "Data Split into Train and Test Sets - Time Elapsed: 0:00:01.132316\n",
            "Preprocessing Applied - Time Elapsed: 0:00:01.213139\n",
            "Logistic Regression - Accuracy: 0.992, F1 Score: 0.9949685534591195\n",
            "Random Forest - Accuracy: 0.9995, F1 Score: 0.9996852376455775\n",
            "AdaBoost - Accuracy: 0.9995, F1 Score: 0.9996852376455775\n",
            "Gradient Boosting - Accuracy: 0.9995, F1 Score: 0.9996852376455775\n",
            "\n",
            "Process Completed - Time: 0:00:05.309051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Function to record the current time since the overall start\n",
        "def record_time(step_name, overall_start_time):\n",
        "    print(f\"{step_name} - Time Elapsed: {datetime.datetime.now() - overall_start_time}\")\n",
        "\n",
        "# Function to plot the confusion matrix\n",
        "def plot_confusion_matrix(cm, classifier_name):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix for {classifier_name}')\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "\n",
        "# Function to plot ROC curve\n",
        "def plot_roc_curve(y_true, y_scores, classifier_name):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve for {classifier_name}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "# Function to label network traffic\n",
        "def label_network_traffic_updated(df):\n",
        "    df['traffic_label'] = 'normal'\n",
        "\n",
        "    # Define thresholds and suspicious indicators\n",
        "    suspicious_ports = set(range(49152, 65536))  # Dynamic/private ports\n",
        "    high_pkt_count_threshold = 5000\n",
        "    high_data_volume_threshold = 5*10**6\n",
        "    short_duration_threshold = 500  # Very short flows in milliseconds\n",
        "    long_duration_threshold = 3600000  # 1 hour\n",
        "    large_packet_size_threshold = 1500  # Larger than typical MTU size\n",
        "\n",
        "    # Lists of services, protocols, and categories that might be suspicious\n",
        "    suspicious_web_services = ['Unknown']\n",
        "    suspicious_protocols = ['Unknown']\n",
        "    suspicious_categories = ['Mining', 'RemoteAccess', 'Unspecified']\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        # Combination of conditions for sophisticated detection\n",
        "        if (\n",
        "            (row['src_port'] in suspicious_ports or row['dst_port'] in suspicious_ports) or\n",
        "            (row['pktTotalCount'] > high_pkt_count_threshold) or\n",
        "            (row['octetTotalCount'] > high_data_volume_threshold) or\n",
        "            (row['flowDuration'] < short_duration_threshold or row['flowDuration'] > long_duration_threshold) or\n",
        "            (max(row['max_ps'], row['min_ps']) > large_packet_size_threshold) or\n",
        "            (row['web_service'] in suspicious_web_services or row['application_protocol'] in suspicious_protocols or row['category'] in suspicious_categories) or\n",
        "            (row['category'] == 'Network' and row['src_prefix'] != 'local' and row['dst_prefix'] != 'local') or\n",
        "            (row['category'] == 'VPN' and row['src_prefix'] != 'local' and row['dst_prefix'] != 'local') or\n",
        "            (row['category'] == 'RemoteAccess' and row['src_prefix'] != 'local' and row['dst_prefix'] != 'local')\n",
        "        ):\n",
        "            df.at[index, 'traffic_label'] = 'malicious'\n",
        "\n",
        "    return df\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('Unicauca-dataset-April-June-2019-Network-flows-50000rows(ALLFEATURES).csv')\n",
        "overall_start_time = datetime.datetime.now()\n",
        "record_time(\"Dataset Loaded\", overall_start_time)\n",
        "\n",
        "# Apply the labeling function\n",
        "df = label_network_traffic_updated(df)\n",
        "record_time(\"Labeling Function Applied\", overall_start_time)\n",
        "# Display the unique classes in the dataset\n",
        "unique_classes = df['traffic_label'].unique()\n",
        "print(\"Unique classes in the dataset:\", unique_classes)\n",
        "\n",
        "# Encoding categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['category_encoded'] = label_encoder.fit_transform(df['traffic_label'])\n",
        "record_time(\"Categorical Labels Encoded\", overall_start_time)\n",
        "\n",
        "# Feature selection and splitting data\n",
        "X = df.drop(columns=['traffic_label', 'category_encoded'])\n",
        "y = df['category_encoded']\n",
        "\n",
        "# Apply SMOTE for oversampling\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n",
        "record_time(\"Data Split into Train and Test Sets\", overall_start_time)\n",
        "\n",
        "# Preprocessing: Handle missing values and scale data\n",
        "numeric_columns = X_train.select_dtypes(include=[np.number]).columns\n",
        "X_train_numeric = X_train[numeric_columns]\n",
        "X_test_numeric = X_test[numeric_columns]\n",
        "\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Apply imputation and scaling only to numeric data\n",
        "X_train_imputed = imputer.fit_transform(X_train_numeric)\n",
        "X_test_imputed = imputer.transform(X_test_numeric)\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "record_time(\"Preprocessing Applied\", overall_start_time)\n",
        "\n",
        "# Define classifiers and hyperparameter grids\n",
        "classifiers = {\n",
        "    'Logistic Regression': {\n",
        "        'model': LogisticRegression(max_iter=1000, random_state=42),\n",
        "        'param_grid': {\n",
        "            'C': [0.001, 0.01, 0.1, 1, 10],\n",
        "            'penalty': ['l1', 'l2']\n",
        "        }\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'model': RandomForestClassifier(n_estimators=50, random_state=42),\n",
        "        'param_grid': {\n",
        "            'n_estimators': [10, 50, 100, 200],\n",
        "            'max_depth': [None, 10, 20, 30]\n",
        "        }\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'model': AdaBoostClassifier(n_estimators=50, random_state=42),\n",
        "        'param_grid': {\n",
        "            'n_estimators': [50, 100, 200],\n",
        "            'learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "        }\n",
        "    },\n",
        "    'Gradient Boosting': {\n",
        "        'model': GradientBoostingClassifier(n_estimators=50, random_state=42),\n",
        "        'param_grid': {\n",
        "            'n_estimators': [50, 100, 200],\n",
        "            'learning_rate': [0.001, 0.01, 0.1, 1],\n",
        "            'max_depth': [3, 4, 5]\n",
        "        }\n",
        "    },\n",
        "    'Decision Tree': {\n",
        "        'model': DecisionTreeClassifier(random_state=42),\n",
        "        'param_grid': {\n",
        "            'max_depth': [None, 10, 20, 30],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Perform hyperparameter tuning and cross-validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for name, classifier_info in classifiers.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    clf = classifier_info['model']\n",
        "    param_grid = classifier_info['param_grid']\n",
        "    grid_search = GridSearchCV(clf, param_grid, cv=cv, scoring='f1', n_jobs=-1, verbose=2)\n",
        "    grid_search.fit(X_train_scaled, y_train)\n",
        "    best_clf = grid_search.best_estimator_\n",
        "    y_pred = best_clf.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print(f\"{name} - Best Parameters: {grid_search.best_params_}\")\n",
        "    print(f\"{name} - Accuracy: {accuracy}, F1 Score: {f1}\")\n",
        "    # Additional evaluation metrics can be added here\n",
        "\n",
        "print(\"\\nProcess Completed - Time:\", datetime.datetime.now() - overall_start_time)\n"
      ],
      "metadata": {
        "id": "ET-Ur_sR0kg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ejaUWHJWuWAT",
        "outputId": "f84bfc4f-bd21-4bbb-8736-ff68b682186c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dbd3fe74-fd13-40ab-a1f2-8bf27533873d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dbd3fe74-fd13-40ab-a1f2-8bf27533873d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Unicauca-dataset-April-June-2019-Network-flows-10000rows(ALLFEATURES).csv to Unicauca-dataset-April-June-2019-Network-flows-10000rows(ALLFEATURES) (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Function to record the current time since the overall start\n",
        "def record_time(step_name, overall_start_time):\n",
        "    print(f\"{step_name} - Time Elapsed: {datetime.datetime.now() - overall_start_time}\")\n",
        "\n",
        "# Function to plot the confusion matrix\n",
        "def plot_confusion_matrix(cm, classifier_name):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix for {classifier_name}')\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "\n",
        "# Function to plot ROC curve\n",
        "def plot_roc_curve(y_true, y_scores, classifier_name):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve for {classifier_name}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('Unicauca-dataset-April-June-2019-Network-flows-25000rows(ALLFEATURES).csv')\n",
        "\n",
        "# Start the overall timer\n",
        "overall_start_time = datetime.datetime.now()\n",
        "record_time(\"Dataset Loaded\", overall_start_time)\n",
        "\n",
        "def label_traffic(df):\n",
        "    # Define normal thresholds\n",
        "    normal_protocols = [6, 17, 1]  # TCP and UDP\n",
        "    normal_port_range = set(range(0, 49152))\n",
        "    normal_pkt_count_max = 2000\n",
        "    normal_octet_count_max = 1000000\n",
        "    normal_packet_size_range = range(20, 1500)\n",
        "    normal_flow_duration_range = range(50, 3600000)  # 50 ms to 1 hour\n",
        "    normal_piat_range = range(0, 10000)  # 0 to 10 seconds\n",
        "    max_timestamp = int(1e12)  # Assuming timestamp in milliseconds\n",
        "\n",
        "    # Initialize the traffic_label column\n",
        "    df['traffic_label'] = 'normal'\n",
        "\n",
        "    # Vectorized conditions\n",
        "# Vectorized conditions\n",
        "    df.loc[~df['proto'].isin(normal_protocols), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['flowEndReason'] == 1, 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['src_port'].isin(normal_port_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['dst_port'].isin(normal_port_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['pktTotalCount'] > normal_pkt_count_max, 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['octetTotalCount'] > normal_octet_count_max, 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['min_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['max_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['avg_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['flowDuration'].isin(normal_flow_duration_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['min_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['max_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['avg_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[(df['flowStart'] < 0) | (df['flowStart'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[(df['flowEnd'] < 0) | (df['flowEnd'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['flowEnd'] < df['flowStart'], 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # Process forward and backward flow features\n",
        "    for prefix in ['f_', 'b_']:\n",
        "        df.loc[df[prefix + 'pktTotalCount'] > normal_pkt_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[df[prefix + 'octetTotalCount'] > normal_octet_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'min_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'max_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'flowDuration'].isin(normal_flow_duration_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'min_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'max_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # IP Address checks\n",
        "    normal_src_ip_ranges = ['192.168.', '10.', '172.']\n",
        "    df.loc[df['src_ip'].apply(lambda ip: any(ip.startswith(range) for range in normal_src_ip_ranges)), 'traffic_label'] = 'normal'\n",
        "    df.loc[df['dst_ip'].apply(lambda ip: any(ip.startswith(range) for range in normal_src_ip_ranges)), 'traffic_label'] = 'normal'\n",
        "\n",
        "    # Web service, application protocol, and category checks\n",
        "    normal_web_services = ['Google', 'Microsoft', 'HTTP', 'DNS', 'Amazon', 'MSN', 'TLS', 'Yahoo', 'DHCP', 'WindowsUpdate', 'NetBIOS', 'RX', 'MS_OneDrive', 'GMail', 'Dropbox', 'GoogleServices', 'ICMP', 'UbuntuONE', 'GoogleDrive', 'YouTube', 'HTTP_Proxy', 'NTP', 'Apple', 'AppleiTunes', 'AppleStore', 'ApplePush', 'AppleiCloud', 'IMAPS', 'IMO', 'Office365', 'Skype', 'Cloudflare']\n",
        "    normal_application_protocols = ['HTTP', 'TLS', 'DNS', 'QUIC', 'IMAPS', 'STUN', 'SMTPS', 'POPS', 'Skype', 'SMBv23', 'NetBIOS', 'RDP', 'ApplePush', 'MQTT']\n",
        "    normal_categories = ['Network', 'Web', 'SoftwareUpdate', 'RPC', 'System', 'Cloud', 'Mail', 'FTP', 'VPN', 'RemoteAccess', 'Email', 'Media', 'Streaming', 'VoIP', 'Collaborative']\n",
        "\n",
        "    df.loc[~df['web_service'].isin(normal_web_services), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['application_protocol'].isin(normal_application_protocols), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['category'].isin(normal_categories), 'traffic_label'] = 'malicious'\n",
        "\n",
        "\n",
        "    return df\n",
        "# Apply the labeling function to the DataFrame\n",
        "df = label_traffic(df)\n",
        "record_time(\"Labeling Function Applied\", overall_start_time)\n",
        "\n",
        "# Encoding the categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['category_encoded'] = label_encoder.fit_transform(df['traffic_label'])\n",
        "record_time(\"Categorical Labels Encoded\", overall_start_time)\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop(columns=['traffic_label', 'category_encoded'])\n",
        "y = df['category_encoded']\n",
        "record_time(\"Features and Target Variable Defined\", overall_start_time)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "record_time(\"Data Split into Train and Test Sets\", overall_start_time)\n",
        "\n",
        "# Identify non-numeric columns\n",
        "non_numeric_columns = X_train.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "# Remove non-numeric columns for simplicity\n",
        "X_train = X_train.drop(non_numeric_columns, axis=1)\n",
        "X_test = X_test.drop(non_numeric_columns, axis=1)\n",
        "record_time(\"Non-numeric Columns Handled\", overall_start_time)\n",
        "\n",
        "# Apply preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "record_time(\"Preprocessing Applied\", overall_start_time)\n",
        "\n",
        "# Define and fit the classifiers\n",
        "lr_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "rf_clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "ab_clf = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
        "gb_clf = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "lr_clf.fit(X_train_scaled, y_train)\n",
        "dt_clf.fit(X_train_scaled, y_train)\n",
        "rf_clf.fit(X_train_scaled, y_train)\n",
        "ab_clf.fit(X_train_scaled, y_train)\n",
        "gb_clf.fit(X_train_scaled, y_train)\n",
        "record_time(\"Classifiers Fitted\", overall_start_time)\n",
        "\n",
        "# Evaluate models and plot confusion matrices and ROC curves\n",
        "for clf, name in [(lr_clf, 'Logistic Regression'), (dt_clf, 'Decision Tree'), (rf_clf, 'Random Forest'), (ab_clf, 'AdaBoost'), (gb_clf, 'Gradient Boosting')]:\n",
        "    # Predictions and probabilities\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "    y_pred_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plot_confusion_matrix(cm, name)\n",
        "\n",
        "    # ROC curve\n",
        "    plot_roc_curve(y_test, y_pred_proba, name)\n",
        "\n",
        "# Calculate accuracy and F1-score for each model\n",
        "lr_accuracy, lr_f1 = accuracy_score(y_test, lr_clf.predict(X_test_scaled)), f1_score(y_test, lr_clf.predict(X_test_scaled))\n",
        "dt_accuracy, dt_f1 = accuracy_score(y_test, dt_clf.predict(X_test_scaled)), f1_score(y_test, dt_clf.predict(X_test_scaled)) # Decision Tree metrics\n",
        "rf_accuracy, rf_f1 = accuracy_score(y_test, rf_clf.predict(X_test_scaled)), f1_score(y_test, rf_clf.predict(X_test_scaled))\n",
        "ab_accuracy, ab_f1 = accuracy_score(y_test, ab_clf.predict(X_test_scaled)), f1_score(y_test, ab_clf.predict(X_test_scaled))\n",
        "gb_accuracy, gb_f1 = accuracy_score(y_test, gb_clf.predict(X_test_scaled)), f1_score(y_test, gb_clf.predict(X_test_scaled))\n",
        "\n",
        "# Print the results\n",
        "print(\"\\nLogistic Regression Classifier:\\nAccuracy:\", lr_accuracy, \"\\nF1-Score:\", lr_f1)\n",
        "print(\"\\nDecision Tree Classifier:\\nAccuracy:\", dt_accuracy, \"\\nF1-Score:\", dt_f1) # Decision Tree results\n",
        "print(\"\\nRandom Forest Classifier:\\nAccuracy:\", rf_accuracy, \"\\nF1-Score:\", rf_f1)\n",
        "print(\"\\nAdaBoost Classifier:\\nAccuracy:\", ab_accuracy, \"\\nF1-Score:\", ab_f1)\n",
        "print(\"\\nGradient Boosting Classifier:\\nAccuracy:\", gb_accuracy, \"\\nF1-Score:\", gb_f1)\n",
        "print(\"\\nProcess Completed - Time:\", datetime.datetime.now() - overall_start_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "eDD8Fow4ulgX",
        "outputId": "78e062df-0f9f-4798-f6e9-fd2c45250a70"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded - Time Elapsed: 0:00:00.000062\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'float' object has no attribute 'startswith'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-cf6a596f820a>\u001b[0m in \u001b[0;36m<cell line: 112>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;31m# Apply the labeling function to the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_traffic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0mrecord_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Labeling Function Applied\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverall_start_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-cf6a596f820a>\u001b[0m in \u001b[0;36mlabel_traffic\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# IP Address checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mnormal_src_ip_ranges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'192.168.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'10.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.16.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.17.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.18.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.19.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.20.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.21.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.22.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.23.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.24.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.25.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.26.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.27.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.28.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.29.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.30.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.31.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src_ip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_src_ip_ranges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'traffic_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dst_ip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_src_ip_ranges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'traffic_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-cf6a596f820a>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(ip)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# IP Address checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mnormal_src_ip_ranges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'192.168.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'10.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.16.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.17.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.18.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.19.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.20.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.21.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.22.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.23.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.24.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.25.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.26.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.27.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.28.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.29.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.30.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.31.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src_ip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_src_ip_ranges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'traffic_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dst_ip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_src_ip_ranges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'traffic_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-cf6a596f820a>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# IP Address checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mnormal_src_ip_ranges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'192.168.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'10.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.16.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.17.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.18.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.19.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.20.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.21.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.22.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.23.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.24.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.25.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.26.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.27.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.28.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.29.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.30.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.31.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src_ip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_src_ip_ranges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'traffic_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dst_ip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_src_ip_ranges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'traffic_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'startswith'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Method 1: Value Counts\n",
        "print(\"Class distribution in y:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "print(\"\\nClass distribution in y_train:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "# Method 2: Unique Values\n",
        "print(\"\\nUnique classes in y:\")\n",
        "print(np.unique(y))\n",
        "\n",
        "print(\"\\nUnique classes in y_train:\")\n",
        "print(np.unique(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-0sUxRzywjy",
        "outputId": "9955009a-2618-4fce-9280-699689b777f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution in y:\n",
            "0    5359\n",
            "1    4641\n",
            "Name: category_encoded, dtype: int64\n",
            "\n",
            "Class distribution in y_train:\n",
            "0    4287\n",
            "1    3713\n",
            "Name: category_encoded, dtype: int64\n",
            "\n",
            "Unique classes in y:\n",
            "[0 1]\n",
            "\n",
            "Unique classes in y_train:\n",
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Function to record the current time since the overall start\n",
        "def record_time(step_name, overall_start_time):\n",
        "    print(f\"{step_name} - Time Elapsed: {datetime.datetime.now() - overall_start_time}\")\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('Unicauca-dataset-April-June-2019-Network-flows-10000rows(ALLFEATURES).csv')\n",
        "overall_start_time = datetime.datetime.now()\n",
        "record_time(\"Dataset Loaded\", overall_start_time)\n",
        "\n",
        "def label_traffic(df):\n",
        "    # Define normal thresholds\n",
        "    normal_protocols = [6, 17, 1]  # TCP and UDP\n",
        "    normal_port_range = set(range(0, 49152))\n",
        "    normal_pkt_count_max = 2000\n",
        "    normal_octet_count_max = 1000000\n",
        "    normal_packet_size_range = range(20, 1500)\n",
        "    normal_flow_duration_range = range(50, 3600000)  # 50 ms to 1 hour\n",
        "    normal_piat_range = range(0, 10000)  # 0 to 10 seconds\n",
        "    max_timestamp = int(1e12)  # Assuming timestamp in milliseconds\n",
        "\n",
        "    # Initialize the traffic_label column\n",
        "    df['traffic_label'] = 'normal'\n",
        "\n",
        "    # Vectorized conditions\n",
        "# Vectorized conditions\n",
        "    df.loc[~df['proto'].isin(normal_protocols), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['flowEndReason'] == 1, 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['src_port'].isin(normal_port_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['dst_port'].isin(normal_port_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['pktTotalCount'] > normal_pkt_count_max, 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['octetTotalCount'] > normal_octet_count_max, 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['min_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['max_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['avg_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['flowDuration'].isin(normal_flow_duration_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['min_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['max_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['avg_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[(df['flowStart'] < 0) | (df['flowStart'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[(df['flowEnd'] < 0) | (df['flowEnd'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['flowEnd'] < df['flowStart'], 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # Process forward and backward flow features\n",
        "    for prefix in ['f_', 'b_']:\n",
        "        df.loc[df[prefix + 'pktTotalCount'] > normal_pkt_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[df[prefix + 'octetTotalCount'] > normal_octet_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'min_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'max_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'flowDuration'].isin(normal_flow_duration_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'min_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'max_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # IP Address checks\n",
        "    normal_src_ip_ranges = ['192.168.', '10.', '172.16.', '172.17.', '172.18.', '172.19.', '172.20.', '172.21.', '172.22.', '172.23.', '172.24.', '172.25.', '172.26.', '172.27.', '172.28.', '172.29.', '172.30.', '172.31.']\n",
        "    df.loc[df['src_ip'].apply(lambda ip: any(ip.startswith(range) for range in normal_src_ip_ranges)), 'traffic_label'] = 'normal'\n",
        "    df.loc[df['dst_ip'].apply(lambda ip: any(ip.startswith(range) for range in normal_src_ip_ranges)), 'traffic_label'] = 'normal'\n",
        "\n",
        "    # Web service, application protocol, and category checks\n",
        "    normal_web_services = ['Google', 'Microsoft', 'HTTP', 'DNS', 'Amazon', 'MSN', 'TLS', 'Yahoo', 'DHCP', 'WindowsUpdate', 'NetBIOS', 'RX', 'MS_OneDrive', 'GMail', 'Dropbox', 'GoogleServices', 'ICMP', 'UbuntuONE', 'GoogleDrive', 'YouTube', 'HTTP_Proxy', 'NTP', 'Apple', 'AppleiTunes', 'AppleStore', 'ApplePush', 'AppleiCloud', 'IMAPS', 'IMO', 'Office365', 'Skype', 'Cloudflare']\n",
        "    normal_application_protocols = ['HTTP', 'TLS', 'DNS', 'QUIC', 'IMAPS', 'STUN', 'SMTPS', 'POPS', 'Skype', 'SMBv23', 'NetBIOS', 'RDP', 'ApplePush', 'MQTT']\n",
        "    normal_categories = ['Network', 'Web', 'SoftwareUpdate', 'RPC', 'System', 'Cloud', 'Mail', 'FTP', 'VPN', 'RemoteAccess', 'Email', 'Media', 'Streaming', 'VoIP', 'Collaborative']\n",
        "\n",
        "    df.loc[~df['web_service'].isin(normal_web_services), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['application_protocol'].isin(normal_application_protocols), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['category'].isin(normal_categories), 'traffic_label'] = 'malicious'\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        "# Label the traffic data\n",
        "df = label_traffic(df)\n",
        "record_time(\"Labeling Function Applied\", overall_start_time)\n",
        "\n",
        "# Drop the specified columns\n",
        "df = df.drop(columns=['flow_key', 'src_ip', 'dst_ip'])\n",
        "\n",
        "# Encoding other non-numeric features\n",
        "label_encoder = LabelEncoder()\n",
        "df['category'] = label_encoder.fit_transform(df['category'])\n",
        "df['application_protocol'] = label_encoder.fit_transform(df['application_protocol'])\n",
        "df['web_service'] = label_encoder.fit_transform(df['web_service'])\n",
        "\n",
        "# Encoding the categorical labels for traffic_label\n",
        "df['category_encoded'] = label_encoder.fit_transform(df['traffic_label'])\n",
        "record_time(\"Categorical Labels Encoded\", overall_start_time)\n",
        "df['traffic_label_encoded'] = label_encoder.fit_transform(df['traffic_label'])\n",
        "\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop(columns=['traffic_label', 'category_encoded'])\n",
        "y = df['category_encoded']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Apply SMOTE to the training data\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "record_time(\"SMOTE Applied\", overall_start_time)\n",
        "\n",
        "# Impute and scale the data\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "scaler = StandardScaler()\n",
        "X_train_imputed = imputer.fit_transform(X_train_res)\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "\n",
        "# Define classifiers and their hyperparameter grids\n",
        "classifiers = {\n",
        "    \"LogisticRegression\": LogisticRegression(random_state=42),\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=42),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(random_state=42),\n",
        "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=42),\n",
        "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    \"LogisticRegression\": {\n",
        "        'C': [0.01, 0.1, 1, 10, 100],  # Range of regularization values\n",
        "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "        'max_iter': [1000, 2000]  # Increased number of iterations\n",
        "    },\n",
        "    \"DecisionTreeClassifier\": {\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    },\n",
        "    \"RandomForestClassifier\": {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    \"AdaBoostClassifier\": {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'learning_rate': [0.01, 0.1, 1]\n",
        "    },\n",
        "    \"GradientBoostingClassifier\": {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'learning_rate': [0.01, 0.1, 1],\n",
        "        'max_depth': [3, 5, 10]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Perform hyperparameter tuning for each classifier\n",
        "best_params = {}\n",
        "for name, clf in classifiers.items():\n",
        "    grid_search = GridSearchCV(clf, param_grids[name], cv=5, scoring='accuracy')\n",
        "    grid_search.fit(X_train_scaled, y_train_res)\n",
        "    best_params[name] = grid_search.best_params_\n",
        "    print(f\"Best parameters for {name}:\", grid_search.best_params_)\n",
        "\n",
        "# Train and evaluate each classifier with best parameters\n",
        "for name, clf in classifiers.items():\n",
        "    clf.set_params(**best_params[name])\n",
        "    clf.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(clf, X_train_scaled, y_train_res, cv=5, scoring='accuracy')\n",
        "    print(f\"{name}: Mean CV Accuracy: {cv_scores.mean()}, Standard Deviation: {cv_scores.std()}\")\n",
        "\n",
        "    # Predictions on test set\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "    y_pred_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # Evaluation metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc = roc_auc_score(y_test, y_pred_proba)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\n{name} Classifier:\")\n",
        "    print(\"Accuracy:\", accuracy, \"\\nF1-Score:\", f1, \"\\nROC AUC:\", roc)\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "print(\"\\nProcess Completed - Time:\", datetime.datetime.now() - overall_start_time)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSF05FIB2bbe",
        "outputId": "a07d1edf-4d89-4855-b986-8f4fa670906f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded - Time Elapsed: 0:00:00.000074\n",
            "Labeling Function Applied - Time Elapsed: 0:00:07.100518\n",
            "Categorical Labels Encoded - Time Elapsed: 0:00:07.123719\n",
            "SMOTE Applied - Time Elapsed: 0:00:07.300050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for LogisticRegression: {'C': 100, 'max_iter': 2000, 'solver': 'sag'}\n",
            "Best parameters for DecisionTreeClassifier: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
            "Best parameters for RandomForestClassifier: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 150}\n",
            "Best parameters for AdaBoostClassifier: {'learning_rate': 1, 'n_estimators': 100}\n",
            "Best parameters for GradientBoostingClassifier: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression: Mean CV Accuracy: 0.9909031097019572, Standard Deviation: 0.0026737689663330587\n",
            "\n",
            "LogisticRegression Classifier:\n",
            "Accuracy: 0.9925 \n",
            "F1-Score: 0.9919743178170143 \n",
            "ROC AUC: 0.9979574112197633\n",
            "Confusion Matrix:\n",
            " [[1058   14]\n",
            " [   1  927]]\n",
            "DecisionTreeClassifier: Mean CV Accuracy: 0.9962664525720273, Standard Deviation: 0.005747477922595849\n",
            "\n",
            "DecisionTreeClassifier Classifier:\n",
            "Accuracy: 1.0 \n",
            "F1-Score: 1.0 \n",
            "ROC AUC: 1.0\n",
            "Confusion Matrix:\n",
            " [[1072    0]\n",
            " [   0  928]]\n",
            "RandomForestClassifier: Mean CV Accuracy: 0.9974341982167095, Standard Deviation: 0.0011424733583608338\n",
            "\n",
            "RandomForestClassifier Classifier:\n",
            "Accuracy: 0.9985 \n",
            "F1-Score: 0.9983862291554599 \n",
            "ROC AUC: 0.999961299375965\n",
            "Confusion Matrix:\n",
            " [[1069    3]\n",
            " [   0  928]]\n",
            "AdaBoostClassifier: Mean CV Accuracy: 0.9969665692581418, Standard Deviation: 0.00440335940618503\n",
            "\n",
            "AdaBoostClassifier Classifier:\n",
            "Accuracy: 1.0 \n",
            "F1-Score: 1.0 \n",
            "ROC AUC: 1.0\n",
            "Confusion Matrix:\n",
            " [[1072    0]\n",
            " [   0  928]]\n",
            "GradientBoostingClassifier: Mean CV Accuracy: 0.9977840524441148, Standard Deviation: 0.0017059196104296911\n",
            "\n",
            "GradientBoostingClassifier Classifier:\n",
            "Accuracy: 1.0 \n",
            "F1-Score: 1.0 \n",
            "ROC AUC: 1.0\n",
            "Confusion Matrix:\n",
            " [[1072    0]\n",
            " [   0  928]]\n",
            "\n",
            "Process Completed - Time: 0:27:34.563102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Method 1: Value Counts\n",
        "print(\"Class distribution in y:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "print(\"\\nClass distribution in y_train:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "# Method 2: Unique Values\n",
        "print(\"\\nUnique classes in y:\")\n",
        "print(np.unique(y))\n",
        "\n",
        "print(\"\\nUnique classes in y_train:\")\n",
        "print(np.unique(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyhPdpvG2cn2",
        "outputId": "d8a8ff46-0d68-463d-cdcf-ad488892d072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution in y:\n",
            "0    5359\n",
            "1    4641\n",
            "Name: category_encoded, dtype: int64\n",
            "\n",
            "Class distribution in y_train:\n",
            "0    4287\n",
            "1    3713\n",
            "Name: category_encoded, dtype: int64\n",
            "\n",
            "Unique classes in y:\n",
            "[0 1]\n",
            "\n",
            "Unique classes in y_train:\n",
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding the target variable for correlation analysis\n",
        "df_encoded = df.copy()\n",
        "label_encoder = LabelEncoder()\n",
        "df_encoded['traffic_label_encoded'] = label_encoder.fit_transform(df_encoded['traffic_label'])\n",
        "\n",
        "# Dropping non-numeric columns for correlation analysis\n",
        "df_encoded = df_encoded.select_dtypes(include=[np.number])\n",
        "\n",
        "# Calculate correlations\n",
        "correlations = df_encoded.corrwith(df_encoded['traffic_label_encoded']).sort_values(ascending=False)\n",
        "\n",
        "# Display correlations\n",
        "correlations.drop('traffic_label_encoded', inplace=True)  # Drop self-correlation\n",
        "correlations\n",
        "# Converting the correlations to a string for easy copying\n",
        "correlations_str = correlations.to_string()\n",
        "correlations_str\n"
      ],
      "metadata": {
        "id": "NsvbyH6De2BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Function to record the current time since the overall start\n",
        "def record_time(step_name, overall_start_time):\n",
        "    print(f\"{step_name} - Time Elapsed: {datetime.datetime.now() - overall_start_time}\")\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('Unicauca-dataset-April-June-2019-Network-flows-10000rows(ALLFEATURES).csv')\n",
        "overall_start_time = datetime.datetime.now()\n",
        "record_time(\"Dataset Loaded\", overall_start_time)\n",
        "\n",
        "def label_traffic(df):\n",
        "    # Define normal thresholds\n",
        "    normal_protocols = [6, 17, 1]  # TCP and UDP\n",
        "    normal_port_range = set(range(0, 49152))\n",
        "    normal_pkt_count_max = 2000\n",
        "    normal_octet_count_max = 1000000\n",
        "    normal_packet_size_range = range(20, 1500)\n",
        "    normal_flow_duration_range = range(50, 3600000)  # 50 ms to 1 hour\n",
        "    normal_piat_range = range(0, 10000)  # 0 to 10 seconds\n",
        "    max_timestamp = int(1e12)  # Assuming timestamp in milliseconds\n",
        "\n",
        "    # Initialize the traffic_label column\n",
        "    df['traffic_label'] = 'normal'\n",
        "\n",
        "    # Vectorized conditions\n",
        "    df.loc[~df['proto'].isin(normal_protocols), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['flowEndReason'] == 1, 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['src_port'].isin(normal_port_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['dst_port'].isin(normal_port_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['pktTotalCount'] > normal_pkt_count_max, 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['octetTotalCount'] > normal_octet_count_max, 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['min_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['max_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['avg_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['flowDuration'].isin(normal_flow_duration_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['min_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['max_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['avg_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[(df['flowStart'] < 0) | (df['flowStart'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[(df['flowEnd'] < 0) | (df['flowEnd'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['flowEnd'] < df['flowStart'], 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # Process forward and backward flow features\n",
        "    for prefix in ['f_', 'b_']:\n",
        "        df.loc[df[prefix + 'pktTotalCount'] > normal_pkt_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[df[prefix + 'octetTotalCount'] > normal_octet_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'min_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'max_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'flowDuration'].isin(normal_flow_duration_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'min_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'max_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # IP Address checks\n",
        "    normal_src_ip_ranges = ['192.168.', '10.', '172.16.', '172.17.', '172.18.', '172.19.', '172.20.', '172.21.', '172.22.', '172.23.', '172.24.', '172.25.', '172.26.', '172.27.', '172.28.', '172.29.', '172.30.', '172.31.']\n",
        "    df.loc[df['src_ip'].apply(lambda ip: any(ip.startswith(range) for range in normal_src_ip_ranges)), 'traffic_label'] = 'normal'\n",
        "    df.loc[df['dst_ip'].apply(lambda ip: any(ip.startswith(range) for range in normal_src_ip_ranges)), 'traffic_label'] = 'normal'\n",
        "\n",
        "    # Web service, application protocol, and category checks\n",
        "    normal_web_services = ['Google', 'Microsoft', 'HTTP', 'DNS', 'Amazon', 'MSN', 'TLS', 'Yahoo', 'DHCP', 'WindowsUpdate', 'NetBIOS', 'RX', 'MS_OneDrive', 'GMail', 'Dropbox', 'GoogleServices', 'ICMP', 'UbuntuONE', 'GoogleDrive', 'YouTube', 'HTTP_Proxy', 'NTP', 'Apple', 'AppleiTunes', 'AppleStore', 'ApplePush', 'AppleiCloud', 'IMAPS', 'IMO', 'Office365', 'Skype', 'Cloudflare']\n",
        "    normal_application_protocols = ['HTTP', 'TLS', 'DNS', 'QUIC', 'IMAPS', 'STUN', 'SMTPS', 'POPS', 'Skype', 'SMBv23', 'NetBIOS', 'RDP', 'ApplePush', 'MQTT']\n",
        "    normal_categories = ['Network', 'Web', 'SoftwareUpdate', 'RPC', 'System', 'Cloud', 'Mail', 'FTP', 'VPN', 'RemoteAccess', 'Email', 'Media', 'Streaming', 'VoIP', 'Collaborative']\n",
        "\n",
        "    df.loc[~df['web_service'].isin(normal_web_services), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['application_protocol'].isin(normal_application_protocols), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['category'].isin(normal_categories), 'traffic_label'] = 'malicious'\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        "# Label the traffic data\n",
        "df = label_traffic(df)\n",
        "record_time(\"Labeling Function Applied\", overall_start_time)\n",
        "\n",
        "# Drop the specified columns\n",
        "df = df.drop(columns=['flow_key', 'src_ip', 'dst_ip'])\n",
        "\n",
        "# Encoding other non-numeric features\n",
        "label_encoder = LabelEncoder()\n",
        "df['category'] = label_encoder.fit_transform(df['category'])\n",
        "df['application_protocol'] = label_encoder.fit_transform(df['application_protocol'])\n",
        "df['web_service'] = label_encoder.fit_transform(df['web_service'])\n",
        "\n",
        "# Encoding the categorical labels for traffic_label\n",
        "df['category_encoded'] = label_encoder.fit_transform(df['traffic_label'])\n",
        "record_time(\"Categorical Labels Encoded\", overall_start_time)\n",
        "\n",
        "# Define features and target variable\n",
        "# Define X and Y\n",
        "X = df.drop(columns=['flow_key', 'src_ip', 'dst_ip', 'traffic_label'])\n",
        "y = df['traffic_label']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Apply SMOTE to the training data\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "record_time(\"SMOTE Applied\", overall_start_time)\n",
        "\n",
        "# Impute and scale the data\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "scaler = StandardScaler()\n",
        "X_train_imputed = imputer.fit_transform(X_train_res)\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "\n",
        "# Define classifiers and their hyperparameter grids\n",
        "classifiers = {\n",
        "    \"LogisticRegression\": LogisticRegression(random_state=42),\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=42),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(random_state=42),\n",
        "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=42),\n",
        "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    \"LogisticRegression\": {\n",
        "        'C': [0.01, 0.1, 1, 10, 100],  # Range of regularization values\n",
        "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "        'max_iter': [1000, 2000]  # Increased number of iterations\n",
        "    },\n",
        "    \"DecisionTreeClassifier\": {\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    },\n",
        "    \"RandomForestClassifier\": {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    \"AdaBoostClassifier\": {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'learning_rate': [0.01, 0.1, 1]\n",
        "    },\n",
        "    \"GradientBoostingClassifier\": {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'learning_rate': [0.01, 0.1, 1],\n",
        "        'max_depth': [3, 5, 10]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Perform hyperparameter tuning for each classifier\n",
        "best_params = {}\n",
        "for name, clf in classifiers.items():\n",
        "    grid_search = GridSearchCV(clf, param_grids[name], cv=5, scoring='accuracy')\n",
        "    grid_search.fit(X_train_scaled, y_train_res)\n",
        "    best_params[name] = grid_search.best_params_\n",
        "    print(f\"Best parameters for {name}:\", grid_search.best_params_)\n",
        "\n",
        "# Train and evaluate each classifier with best parameters\n",
        "for name, clf in classifiers.items():\n",
        "    clf.set_params(**best_params[name])\n",
        "    clf.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(clf, X_train_scaled, y_train_res, cv=5, scoring='accuracy')\n",
        "    print(f\"{name}: Mean CV Accuracy: {cv_scores.mean()}, Standard Deviation: {cv_scores.std()}\")\n",
        "\n",
        "    # Predictions on test set\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "    y_pred_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # Evaluation metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc = roc_auc_score(y_test, y_pred_proba)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\n{name} Classifier:\")\n",
        "    print(\"Accuracy:\", accuracy, \"\\nF1-Score:\", f1, \"\\nROC AUC:\", roc)\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "print(\"\\nProcess Completed - Time:\", datetime.datetime.now() - overall_start_time)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1E6I0UsPhQk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Function to record the current time since the overall start\n",
        "def record_time(step_name, overall_start_time):\n",
        "    print(f\"{step_name} - Time Elapsed: {datetime.datetime.now() - overall_start_time}\")\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('Unicauca-dataset-April-June-2019-Network-flows-25000rows(ALLFEATURES).csv')\n",
        "overall_start_time = datetime.datetime.now()\n",
        "record_time(\"Dataset Loaded\", overall_start_time)\n",
        "\n",
        "# Apply the labeling function to label the traffic data\n",
        "def label_traffic(df):\n",
        "    # Define normal thresholds\n",
        "    normal_protocols = [6, 17, 1]  # TCP and UDP\n",
        "    normal_port_range = set(range(0, 49152))\n",
        "    normal_pkt_count_max = 2000\n",
        "    normal_octet_count_max = 1000000\n",
        "    normal_packet_size_range = range(20, 1500)\n",
        "    normal_flow_duration_range = range(50, 3600000)  # 50 ms to 1 hour\n",
        "    normal_piat_range = range(0, 10000)  # 0 to 10 seconds\n",
        "    max_timestamp = int(1e12)  # Assuming timestamp in milliseconds\n",
        "\n",
        "    # Initialize the traffic_label column\n",
        "    df['traffic_label'] = 'normal'\n",
        "\n",
        "    # Vectorized conditions\n",
        "    df.loc[~df['proto'].isin(normal_protocols), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['flowEndReason'] == 1, 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['src_port'].isin(normal_port_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['dst_port'].isin(normal_port_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['pktTotalCount'] > normal_pkt_count_max, 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['octetTotalCount'] > normal_octet_count_max, 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['min_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['max_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['avg_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['flowDuration'].isin(normal_flow_duration_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['min_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['max_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['avg_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[(df['flowStart'] < 0) | (df['flowStart'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[(df['flowEnd'] < 0) | (df['flowEnd'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['flowEnd'] < df['flowStart'], 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # Process forward and backward flow features\n",
        "    for prefix in ['f_', 'b_']:\n",
        "        df.loc[df[prefix + 'pktTotalCount'] > normal_pkt_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[df[prefix + 'octetTotalCount'] > normal_octet_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'min_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'max_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'flowDuration'].isin(normal_flow_duration_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'min_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'max_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # IP Address checks\n",
        "    normal_src_ip_ranges = ['192.168.', '10.', '172.16.', '172.17.', '172.18.', '172.19.', '172.20.', '172.21.', '172.22.', '172.23.', '172.24.', '172.25.', '172.26.', '172.27.', '172.28.', '172.29.', '172.30.', '172.31.']\n",
        "    df.loc[df['src_ip'].apply(lambda ip: any(ip.startswith(range) for range in normal_src_ip_ranges)), 'traffic_label'] = 'normal'\n",
        "    df.loc[df['dst_ip'].apply(lambda ip: any(ip.startswith(range) for range in normal_src_ip_ranges)), 'traffic_label'] = 'normal'\n",
        "\n",
        "    # Web service, application protocol, and category checks\n",
        "    normal_web_services = ['Google', 'Microsoft', 'HTTP', 'DNS', 'Amazon', 'MSN', 'TLS', 'Yahoo', 'DHCP', 'WindowsUpdate', 'NetBIOS', 'RX', 'MS_OneDrive', 'GMail', 'Dropbox', 'GoogleServices', 'ICMP', 'UbuntuONE', 'GoogleDrive', 'YouTube', 'HTTP_Proxy', 'NTP', 'Apple', 'AppleiTunes', 'AppleStore', 'ApplePush', 'AppleiCloud', 'IMAPS', 'IMO', 'Office365', 'Skype', 'Cloudflare']\n",
        "    normal_application_protocols = ['HTTP', 'TLS', 'DNS', 'QUIC', 'IMAPS', 'STUN', 'SMTPS', 'POPS', 'Skype', 'SMBv23', 'NetBIOS', 'RDP', 'ApplePush', 'MQTT']\n",
        "    normal_categories = ['Network', 'Web', 'SoftwareUpdate', 'RPC', 'System', 'Cloud', 'Mail', 'FTP', 'VPN', 'RemoteAccess', 'Email', 'Media', 'Streaming', 'VoIP', 'Collaborative']\n",
        "\n",
        "    df.loc[~df['web_service'].isin(normal_web_services), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['application_protocol'].isin(normal_application_protocols), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['category'].isin(normal_categories), 'traffic_label'] = 'malicious'\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        "df = label_traffic(df)\n",
        "record_time(\"Labeling Function Applied\", overall_start_time)\n",
        "\n",
        "# Drop the specified columns\n",
        "df = df.drop(columns=['flow_key', 'src_ip', 'dst_ip'])\n",
        "\n",
        "# Encoding other non-numeric features\n",
        "label_encoder = LabelEncoder()\n",
        "df['category'] = label_encoder.fit_transform(df['category'])\n",
        "df['application_protocol'] = label_encoder.fit_transform(df['application_protocol'])\n",
        "df['web_service'] = label_encoder.fit_transform(df['web_service'])\n",
        "\n",
        "# Encoding the categorical labels for traffic_label\n",
        "label_encoder = LabelEncoder()\n",
        "df['category_encoded'] = label_encoder.fit_transform(df['traffic_label'])\n",
        "\n",
        "# Remove the 'category' column\n",
        "df = df.drop(columns=['category'])\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop(columns=['traffic_label', 'category_encoded'])\n",
        "y = df['category_encoded']\n",
        "\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Apply SMOTE to the training data\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "record_time(\"SMOTE Applied\", overall_start_time)\n",
        "\n",
        "# Impute and scale the data\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "scaler = StandardScaler()\n",
        "X_train_imputed = imputer.fit_transform(X_train_res)\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "\n",
        "# Define classifiers and their hyperparameter grids\n",
        "classifiers = {\n",
        "    \"LogisticRegression\": LogisticRegression(random_state=42),\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=42),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(random_state=42),\n",
        "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=42),\n",
        "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    \"LogisticRegression\": {\n",
        "        'C': [0.01, 0.1, 1, 10, 100],\n",
        "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "        'max_iter': [1000, 2000, 3000]  # Increase the number of iterations\n",
        "    },\n",
        "\n",
        "    \"DecisionTreeClassifier\": {\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    },\n",
        "    \"RandomForestClassifier\": {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    \"AdaBoostClassifier\": {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'learning_rate': [0.01, 0.1, 1]\n",
        "    },\n",
        "    \"GradientBoostingClassifier\": {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'learning_rate': [0.01, 0.1, 1],\n",
        "        'max_depth': [3, 5, 10]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Perform hyperparameter tuning for each classifier\n",
        "best_params = {}\n",
        "for name, clf in classifiers.items():\n",
        "    grid_search = GridSearchCV(clf, param_grids[name], cv=5, scoring='accuracy')\n",
        "    grid_search.fit(X_train_scaled, y_train_res)\n",
        "    best_params[name] = grid_search.best_params_\n",
        "    print(f\"Best parameters for {name}:\", grid_search.best_params_)\n",
        "\n",
        "# Train and evaluate each classifier with best parameters\n",
        "for name, clf in classifiers.items():\n",
        "    clf.set_params(**best_params[name])\n",
        "    clf.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(clf, X_train_scaled, y_train_res, cv=5, scoring='accuracy')\n",
        "    print(f\"{name}: Mean CV Accuracy: {cv_scores.mean()}, Standard Deviation: {cv_scores.std()}\")\n",
        "\n",
        "# Predictions on test set\n",
        "y_pred = clf.predict(X_test_scaled)\n",
        "y_pred_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc = roc_auc_score(y_test, y_pred_proba)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\n{name} Classifier:\")\n",
        "print(\"Accuracy:\", accuracy, \"\\nF1-Score:\", f1, \"\\nROC AUC:\", roc)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"\\nProcess Completed - Time:\", datetime.datetime.now() - overall_start_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "KXKSH9NloXTE",
        "outputId": "46a58966-906c-43ef-c9c6-f2dc4af0b95e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded - Time Elapsed: 0:00:00.000047\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'float' object has no attribute 'startswith'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-9cded5dd578f>\u001b[0m in \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_traffic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0mrecord_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Labeling Function Applied\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverall_start_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-9cded5dd578f>\u001b[0m in \u001b[0;36mlabel_traffic\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# IP Address checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mnormal_src_ip_ranges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'192.168.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'10.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.16.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.17.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.18.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.19.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.20.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.21.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.22.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.23.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.24.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.25.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.26.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.27.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.28.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.29.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.30.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.31.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src_ip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_src_ip_ranges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'traffic_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dst_ip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_src_ip_ranges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'traffic_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-9cded5dd578f>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(ip)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# IP Address checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mnormal_src_ip_ranges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'192.168.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'10.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.16.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.17.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.18.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.19.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.20.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.21.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.22.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.23.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.24.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.25.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.26.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.27.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.28.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.29.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.30.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.31.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src_ip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_src_ip_ranges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'traffic_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dst_ip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_src_ip_ranges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'traffic_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-9cded5dd578f>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# IP Address checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mnormal_src_ip_ranges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'192.168.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'10.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.16.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.17.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.18.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.19.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.20.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.21.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.22.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.23.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.24.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.25.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.26.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.27.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.28.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.29.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.30.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'172.31.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src_ip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_src_ip_ranges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'traffic_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dst_ip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_src_ip_ranges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'traffic_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'startswith'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Method 1: Value Counts\n",
        "print(\"Class distribution in y:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "print(\"\\nClass distribution in y_train:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "# Method 2: Unique Values\n",
        "print(\"\\nUnique classes in y:\")\n",
        "print(np.unique(y))\n",
        "\n",
        "print(\"\\nUnique classes in y_train:\")\n",
        "print(np.unique(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "K0VYbLGizsPH",
        "outputId": "f902ea03-0d99-41a6-dabb-bc9b13dcdd45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution in y:\n",
            "malicious    10000\n",
            "Name: traffic_label, dtype: int64\n",
            "\n",
            "Class distribution in y_train:\n",
            "malicious    8000\n",
            "Name: traffic_label, dtype: int64\n",
            "\n",
            "Unique classes in y:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-9a12f8e921f1>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Method 2: Unique Values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nUnique classes in y:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nUnique classes in y_train:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# Apply the labeling function to label the traffic data\n",
        "def label_traffic(df):\n",
        "    # Define normal thresholds\n",
        "    normal_protocols = [6, 17, 1]  # TCP and UDP\n",
        "    normal_port_range = set(range(0, 49152))\n",
        "    normal_pkt_count_max = 2000\n",
        "    normal_octet_count_max = 1000000\n",
        "    normal_packet_size_range = range(20, 1500)\n",
        "    normal_flow_duration_range = range(50, 3600000)  # 50 ms to 1 hour\n",
        "    normal_piat_range = range(0, 10000)  # 0 to 10 seconds\n",
        "    max_timestamp = int(1e12)  # Assuming timestamp in milliseconds\n",
        "\n",
        "    # Initialize the traffic_label column\n",
        "    df['traffic_label'] = 'normal'\n",
        "\n",
        "    # Vectorized conditions\n",
        "    df.loc[~df['proto'].isin(normal_protocols), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['flowEndReason'] == 1, 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['src_port'].isin(normal_port_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['dst_port'].isin(normal_port_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['pktTotalCount'] > normal_pkt_count_max, 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['octetTotalCount'] > normal_octet_count_max, 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['min_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['max_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['avg_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['flowDuration'].isin(normal_flow_duration_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['min_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['max_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['avg_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[(df['flowStart'] < 0) | (df['flowStart'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[(df['flowEnd'] < 0) | (df['flowEnd'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['flowEnd'] < df['flowStart'], 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # Process forward and backward flow features\n",
        "    for prefix in ['f_', 'b_']:\n",
        "        df.loc[df[prefix + 'pktTotalCount'] > normal_pkt_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[df[prefix + 'octetTotalCount'] > normal_octet_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'min_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'max_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'flowDuration'].isin(normal_flow_duration_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'min_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'max_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # IP Address checks\n",
        "    normal_src_ip_ranges = ['192.168.', '10.', '172.16.', '172.17.', '172.18.', '172.19.', '172.20.', '172.21.', '172.22.', '172.23.', '172.24.', '172.25.', '172.26.', '172.27.', '172.28.', '172.29.', '172.30.', '172.31.']\n",
        "    df.loc[df['src_ip'].apply(lambda ip: any(ip.startswith(range) for range in normal_src_ip_ranges)), 'traffic_label'] = 'normal'\n",
        "    df.loc[df['dst_ip'].apply(lambda ip: any(ip.startswith(range) for range in normal_src_ip_ranges)), 'traffic_label'] = 'normal'\n",
        "\n",
        "    # Web service, application protocol, and category checks\n",
        "    normal_web_services = ['Google', 'Microsoft', 'HTTP', 'DNS', 'Amazon', 'MSN', 'TLS', 'Yahoo', 'DHCP', 'WindowsUpdate', 'NetBIOS', 'RX', 'MS_OneDrive', 'GMail', 'Dropbox', 'GoogleServices', 'ICMP', 'UbuntuONE', 'GoogleDrive', 'YouTube', 'HTTP_Proxy', 'NTP', 'Apple', 'AppleiTunes', 'AppleStore', 'ApplePush', 'AppleiCloud', 'IMAPS', 'IMO', 'Office365', 'Skype', 'Cloudflare']\n",
        "    normal_application_protocols = ['HTTP', 'TLS', 'DNS', 'QUIC', 'IMAPS', 'STUN', 'SMTPS', 'POPS', 'Skype', 'SMBv23', 'NetBIOS', 'RDP', 'ApplePush', 'MQTT']\n",
        "    normal_categories = ['Network', 'Web', 'SoftwareUpdate', 'RPC', 'System', 'Cloud', 'Mail', 'FTP', 'VPN', 'RemoteAccess', 'Email', 'Media', 'Streaming', 'VoIP', 'Collaborative']\n",
        "\n",
        "    df.loc[~df['web_service'].isin(normal_web_services), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['application_protocol'].isin(normal_application_protocols), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['category'].isin(normal_categories), 'traffic_label'] = 'malicious'\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        "# Load your dataset here (replace 'your_dataset.csv' with the actual file path)\n",
        "df = pd.read_csv('Unicauca-dataset-April-June-2019-Network-flows-10000rows(ALLFEATURES).csv')\n",
        "\n",
        "# Apply the labeling function to label the traffic data\n",
        "df = label_traffic(df)\n",
        "\n",
        "# Preprocessing\n",
        "# Encode non-numeric features using Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "categorical_columns = ['src_ip', 'dst_ip', 'proto', 'application_protocol', 'web_service', 'traffic_label']\n",
        "for col in categorical_columns:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = df.drop(columns=['flow_key', 'traffic_label', 'flowEndReason', 'category'])\n",
        "y = df['traffic_label']\n",
        "\n",
        "# Standardize numeric features\n",
        "scaler = StandardScaler()\n",
        "# Define the numeric columns you want to standardize\n",
        "numeric_columns = ['src_ip_numeric', 'src_port', 'dst_port', 'pktTotalCount', 'octetTotalCount',\n",
        "                   'min_ps', 'max_ps', 'avg_ps', 'std_dev_ps', 'flowStart', 'flowEnd', 'flowDuration', 'min_piat',\n",
        "                   'max_piat', 'avg_piat', 'std_dev_piat', 'f_pktTotalCount', 'f_octetTotalCount', 'f_min_ps',\n",
        "                   'f_max_ps', 'f_avg_ps', 'f_std_dev_ps', 'f_flowStart', 'f_flowEnd', 'f_flowDuration', 'f_min_piat',\n",
        "                   'f_max_piat', 'f_avg_piat', 'f_std_dev_piat', 'b_pktTotalCount', 'b_octetTotalCount', 'b_min_ps',\n",
        "                   'b_max_ps', 'b_avg_ps', 'b_std_dev_ps', 'b_flowStart', 'b_flowEnd', 'b_flowDuration', 'b_min_piat',\n",
        "                   'b_max_piat', 'b_avg_piat', 'b_std_dev_piat']\n",
        "\n",
        "# Filter only the existing numeric columns in the DataFrame\n",
        "numeric_columns = [col for col in numeric_columns if col in X.columns]\n",
        "\n",
        "# Standardize the numeric features\n",
        "X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
        "\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "logistic_regression = LogisticRegression()\n",
        "logistic_regression.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the Logistic Regression model\n",
        "y_pred_lr = logistic_regression.predict(X_test)\n",
        "\n",
        "# Evaluate the Logistic Regression model\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
        "roc_auc_lr = roc_auc_score(y_test, logistic_regression.predict_proba(X_test)[:, 1])\n",
        "confusion_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "\n",
        "# Print evaluation metrics for Logistic Regression\n",
        "print(\"Logistic Regression Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_lr)\n",
        "print(\"F1-Score:\", f1_lr)\n",
        "print(\"ROC AUC:\", roc_auc_lr)\n",
        "print(\"Confusion Matrix:\\n\", confusion_lr)\n",
        "\n",
        "# Create and train the RandomForestClassifier model\n",
        "random_forest = RandomForestClassifier()\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the RandomForestClassifier model\n",
        "y_pred_rf = random_forest.predict(X_test)\n",
        "\n",
        "# Evaluate the RandomForestClassifier model\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "roc_auc_rf = roc_auc_score(y_test, random_forest.predict_proba(X_test)[:, 1])\n",
        "confusion_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "# Print evaluation metrics for RandomForestClassifier\n",
        "print(\"\\nRandom Forest Classifier Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_rf)\n",
        "print(\"F1-Score:\", f1_rf)\n",
        "print(\"ROC AUC:\", roc_auc_rf)\n",
        "print(\"Confusion Matrix:\\n\", confusion_rf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRyhyuaj1yJ_",
        "outputId": "deaa9895-655a-4cf6-e625-9c7d8b9970e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Metrics:\n",
            "Accuracy: 0.9755\n",
            "F1-Score: 0.9755008803757006\n",
            "ROC AUC: 0.9956424102547606\n",
            "Confusion Matrix:\n",
            " [[1047   25]\n",
            " [  24  904]]\n",
            "\n",
            "Random Forest Classifier Metrics:\n",
            "Accuracy: 0.9985\n",
            "F1-Score: 0.9985001594173439\n",
            "ROC AUC: 0.9996743116314977\n",
            "Confusion Matrix:\n",
            " [[1069    3]\n",
            " [   0  928]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in the dataset\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDYN4efN4Kwe",
        "outputId": "f8637626-e7b2-414d-bdb6-517a9456ad6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flow_key                0\n",
            "src_ip_numeric          0\n",
            "src_ip                  0\n",
            "src_port                0\n",
            "dst_ip                  0\n",
            "dst_port                0\n",
            "proto                   0\n",
            "pktTotalCount           0\n",
            "octetTotalCount         0\n",
            "min_ps                  0\n",
            "max_ps                  0\n",
            "avg_ps                  0\n",
            "std_dev_ps              0\n",
            "flowStart               0\n",
            "flowEnd                 0\n",
            "flowDuration            0\n",
            "min_piat                0\n",
            "max_piat                0\n",
            "avg_piat                0\n",
            "std_dev_piat            0\n",
            "f_pktTotalCount         0\n",
            "f_octetTotalCount       0\n",
            "f_min_ps                0\n",
            "f_max_ps                0\n",
            "f_avg_ps                0\n",
            "f_std_dev_ps            0\n",
            "f_flowStart             0\n",
            "f_flowEnd               0\n",
            "f_flowDuration          0\n",
            "f_min_piat              0\n",
            "f_max_piat              0\n",
            "f_avg_piat              0\n",
            "f_std_dev_piat          0\n",
            "b_pktTotalCount         0\n",
            "b_octetTotalCount       0\n",
            "b_min_ps                0\n",
            "b_max_ps                0\n",
            "b_avg_ps                0\n",
            "b_std_dev_ps            0\n",
            "b_flowStart             0\n",
            "b_flowEnd               0\n",
            "b_flowDuration          0\n",
            "b_min_piat              0\n",
            "b_max_piat              0\n",
            "b_avg_piat              0\n",
            "b_std_dev_piat          0\n",
            "flowEndReason           0\n",
            "category                0\n",
            "application_protocol    0\n",
            "web_service             0\n",
            "traffic_label           0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import socket\n",
        "import struct\n",
        "\n",
        "# Function to convert IP address from numeric format to dotted format\n",
        "def numeric_to_dotted_ip(numeric_ip):\n",
        "    try:\n",
        "        return socket.inet_ntoa(struct.pack('!I', numeric_ip))\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Test the conversion with an example from the dataset\n",
        "example_numeric_ip = 3232266497\n",
        "converted_ip = numeric_to_dotted_ip(example_numeric_ip)\n",
        "print(converted_ip)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAeG4IRtofJS",
        "outputId": "a47c288d-cf9c-44ec-f690-94e744cab5c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "192.168.121.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "sojA-c8VArFQ",
        "outputId": "95f4b3f9-9c4a-4afd-ba79-aa2ae80ad262"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b50b4ec8-b676-40b7-88f0-3c07ec0be559\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b50b4ec8-b676-40b7-88f0-3c07ec0be559\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Unicauca-dataset-April-June-2019-Network-flows-10000rows(ALLFEATURES).csv to Unicauca-dataset-April-June-2019-Network-flows-10000rows(ALLFEATURES).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Function to record the current time since the overall start\n",
        "def record_time(step_name, overall_start_time):\n",
        "    print(f\"{step_name} - Time Elapsed: {datetime.datetime.now() - overall_start_time}\")\n",
        "\n",
        "# Apply the modified labeling function to label the traffic data\n",
        "def label_traffic(df):\n",
        "    # Define normal thresholds\n",
        "    normal_protocols = [6, 17, 1]  # TCP and UDP\n",
        "    normal_port_range = set(range(0, 65536)) #65536   49152\n",
        "    normal_pkt_count_max = 50\n",
        "    normal_octet_count_max = 15000\n",
        "    normal_packet_size_range = range(20, 1500)\n",
        "    normal_piat_range = range(0, 248)  # 0 to  seconds\n",
        "    max_timestamp = int(1e12)  # Assuming timestamp in milliseconds\n",
        "    normal_std_dev_ps_range = range(9, 27)\n",
        "    normal_flow_duration_range = range(1451, 1702)\n",
        "    normal_min_piat_range = range(0, int(0.010356 * 1e6))  # Converting to microseconds if necessary\n",
        "    normal_max_piat_range = range(158, 249)  # Based on max_piat analysis\n",
        "    normal_avg_piat_range = range(1, 107)  # Based on avg_piat analysis\n",
        "    normal_std_dev_piat_range = range(50, 79)  # Based on std_dev_piat analysis\n",
        "\n",
        "    # Initialize the traffic_label column\n",
        "    df['traffic_label'] = 'normal'\n",
        "\n",
        "    # Vectorized conditions\n",
        "    df.loc[~df['proto'].isin(normal_protocols), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['flowEndReason'] == 1, 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['src_port'].isin(normal_port_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['dst_port'].isin(normal_port_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['pktTotalCount'] > normal_pkt_count_max, 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['octetTotalCount'] > normal_octet_count_max, 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['min_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['max_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['avg_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['flowDuration'].isin(normal_flow_duration_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['min_piat'].isin(normal_min_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['max_piat'].isin(normal_max_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['avg_piat'].isin(normal_avg_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_piat'].isin(normal_std_dev_piat_range), 'traffic_label'] = 'malicious'\n",
        "\n",
        "    df.loc[(df['flowStart'] < 0) | (df['flowStart'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[(df['flowEnd'] < 0) | (df['flowEnd'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['flowEnd'] < df['flowStart'], 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # Process forward and backward flow features\n",
        "    for prefix in ['f_', 'b_']:\n",
        "        df.loc[df[prefix + 'pktTotalCount'] > normal_pkt_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[df[prefix + 'octetTotalCount'] > normal_octet_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'min_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'max_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'flowDuration'].isin(normal_flow_duration_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'min_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'max_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_piat'].isin(normal_piat_range), 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # IP Address checks\n",
        "    normal_src_ip_ranges = ['192.168.', '10.', '172.16.', '172.17.', '172.18.', '172.19.', '172.20.', '172.21.', '172.22.', '172.23.', '172.24.', '172.25.', '172.26.', '172.27.', '172.28.', '172.29.', '172.30.', '172.31.']\n",
        "    # Convert 'src_ip' and 'dst_ip' columns to strings\n",
        "    df['src_ip'] = df['src_ip'].astype(str)\n",
        "    df['dst_ip'] = df['dst_ip'].astype(str)\n",
        "\n",
        "    # Then apply your existing conditions\n",
        "    df.loc[df['src_ip'].apply(lambda ip: any(ip.startswith(range) for range in normal_src_ip_ranges)), 'traffic_label'] = 'normal'\n",
        "    df.loc[df['dst_ip'].apply(lambda ip: any(ip.startswith(range) for range in normal_src_ip_ranges)), 'traffic_label'] = 'normal'\n",
        "\n",
        "\n",
        "    # Web service, application protocol, and category checks\n",
        "    normal_web_services = ['DHCP', 'ICMP', 'HTTP', 'Microsoft', 'WindowsUpdate', 'Unknown', 'DNS', 'RX', 'TLS', 'NetBIOS', 'GoogleServices', 'Amazon', 'MSN', 'Yahoo', 'MS_OneDrive', 'Google', 'Dropbox', 'GMail', 'UbuntuONE', 'GoogleDrive', 'YouTube', 'HTTP_Proxy', 'NTP', 'Apple', 'AppleiTunes', 'AppleStore', 'ApplePush', 'AppleiCloud', 'IMAPS', 'IMO', 'Office365', 'Skype', 'Cloudflare', 'Spotify', 'LDAP', 'Twitter', 'Facebook', 'LinkedIn', 'Instagram', 'AmazonVideo', 'GooglePlus', 'Github', 'GoogleDocs', 'Teredo', 'BitTorrent', 'Messenger', 'WhatsApp', 'PlayStore', 'Ookla', 'Unencrypted_Jabber', 'SMBv23', 'Wikipedia', 'QUIC', 'Signal', 'CiscoVPN', 'TeamViewer', 'VNC', 'NetFlix', 'Playstation', 'PS_VUE', 'Xbox', 'GoogleMaps', 'GoogleHangoutDuo', 'MQTT', 'Radius', 'SSH', 'STUN', 'Pando_Media_Booster', 'Whois-DAS', 'H323', 'Webex', 'Oracle', 'DataSaver', 'Steam', 'SNMP', 'WhatsAppCall', 'Syslog', 'Starcraft', 'IPsec', 'SIP', 'RDP', 'MsSQL-TDS', 'OpenDNS', 'SkypeCall', 'Tor', 'RTMP', 'QQ', 'IRC', 'Slack', 'eBay', 'HotspotShield', 'TikTok', 'Snapchat', 'SSDP', 'DNSoverHTTPS', 'SMTP', 'RTP']\n",
        "    normal_application_protocols = ['Unknown', 'HTTP', 'TLS', 'DNS', 'QUIC', 'IMAPS', 'STUN', 'SMTPS', 'POPS', 'Skype', 'SMBv23']\n",
        "    normal_categories = ['Network', 'Web', 'SoftwareUpdate', 'Unspecified', 'RPC', 'System', 'Cloud', 'Email', 'Media', 'Streaming', 'VoIP', 'Collaborative', 'Music', 'SocialNetwork', 'Video', 'Download-FileTransfer-FileSharing', 'Chat', 'VPN', 'RemoteAccess', 'Game', 'Database', 'Shopping']\n",
        "\n",
        "    df.loc[~df['web_service'].isin(normal_web_services), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['application_protocol'].isin(normal_application_protocols), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['category'].isin(normal_categories), 'traffic_label'] = 'malicious'\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        "# Load your dataset here (replace 'your_dataset.csv' with the actual file path)\n",
        "df = pd.read_csv('Unicauca-dataset-April-June-2019-Network-flows-25000rows(ALLFEATURES).csv')\n",
        "record_time(\"Dataset Loaded\", overall_start_time)\n",
        "\n",
        "# Apply the modified labeling function to label the traffic data\n",
        "df = label_traffic(df)\n",
        "record_time(\"Labeling Function Applied\", overall_start_time)\n",
        "\n",
        "# Modified preprocessing step\n",
        "# Identify all categorical columns (excluding the target variable)\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
        "categorical_columns.remove('traffic_label')\n",
        "\n",
        "# Apply label encoding to each categorical column\n",
        "label_encoder = LabelEncoder()\n",
        "for col in categorical_columns:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "record_time(\"Categorical Labels Encoded\", overall_start_time)\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "#X = df.drop(columns=['flow_key', 'traffic_label', 'src_ip', 'min_ps' , 'max_ps', 'avg_ps', 'std_dev_ps']))\n",
        "X = df.drop(columns=['flow_key', 'traffic_label', 'src_ip'])\n",
        "y = df['traffic_label']\n",
        "\n",
        "# Handle NaN values by imputation\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Standardize numeric features\n",
        "scaler = StandardScaler()\n",
        "# Define the numeric columns you want to standardize\n",
        "# Define the numeric columns you want to standardize\n",
        "numeric_columns = [\n",
        "    'src_ip_numeric', 'src_port', 'dst_port', 'pktTotalCount', 'octetTotalCount',\n",
        "    'min_ps', 'max_ps', 'avg_ps', 'std_dev_ps', 'flowStart', 'flowEnd',\n",
        "    'flowDuration', 'min_piat', 'max_piat', 'avg_piat', 'std_dev_piat',\n",
        "    'f_pktTotalCount', 'f_octetTotalCount', 'f_min_ps', 'f_max_ps', 'f_avg_ps',\n",
        "    'f_std_dev_ps', 'f_flowStart', 'f_flowEnd', 'f_flowDuration', 'f_min_piat',\n",
        "    'f_max_piat', 'f_avg_piat', 'f_std_dev_piat', 'b_pktTotalCount',\n",
        "    'b_octetTotalCount', 'b_min_ps', 'b_max_ps', 'b_avg_ps', 'b_std_dev_ps',\n",
        "    'b_flowStart', 'b_flowEnd', 'b_flowDuration', 'b_min_piat', 'b_max_piat',\n",
        "    'b_avg_piat', 'b_std_dev_piat'\n",
        "]\n",
        "\n",
        "# Standardize the numeric features\n",
        "X_imputed = pd.DataFrame(X_imputed, columns=X.columns)  # Convert imputed array back to DataFrame\n",
        "X_imputed[numeric_columns] = scaler.fit_transform(X_imputed[numeric_columns])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "logistic_regression = LogisticRegression()\n",
        "logistic_regression.fit(X_train, y_train)\n",
        "\n",
        "# ... following code ...\n",
        "# Predict using the Logistic Regression model\n",
        "y_pred_lr = logistic_regression.predict(X_test)\n",
        "\n",
        "# Evaluate the Logistic Regression model\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
        "roc_auc_lr = roc_auc_score(y_test, logistic_regression.predict_proba(X_test)[:, 1])\n",
        "confusion_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "\n",
        "# Print evaluation metrics for Logistic Regression\n",
        "print(\"Logistic Regression Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_lr)\n",
        "print(\"F1-Score:\", f1_lr)\n",
        "print(\"ROC AUC:\", roc_auc_lr)\n",
        "print(\"Confusion Matrix:\\n\", confusion_lr)\n",
        "\n",
        "# Create and train the RandomForestClassifier model\n",
        "random_forest = RandomForestClassifier()\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the RandomForestClassifier model\n",
        "y_pred_rf = random_forest.predict(X_test)\n",
        "\n",
        "# Evaluate the RandomForestClassifier model\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "roc_auc_rf = roc_auc_score(y_test, random_forest.predict_proba(X_test)[:, 1])\n",
        "confusion_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "# Print evaluation metrics for RandomForestClassifier\n",
        "print(\"\\nRandom Forest Classifier Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_rf)\n",
        "print(\"F1-Score:\", f1_rf)\n",
        "print(\"ROC AUC:\", roc_auc_rf)\n",
        "print(\"Confusion Matrix:\\n\", confusion_rf)\n",
        "print(\"\\nProcess Completed - Time:\", datetime.datetime.now() - overall_start_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR3oiiuKApaw",
        "outputId": "a4b62ed9-67db-45f0-9fa8-ebc6535451c3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded - Time Elapsed: 2:02:59.702897\n",
            "Labeling Function Applied - Time Elapsed: 2:03:05.710561\n",
            "Categorical Labels Encoded - Time Elapsed: 2:03:08.584397\n",
            "Logistic Regression Metrics:\n",
            "Accuracy: 0.98192\n",
            "F1-Score: 0.9819148719370353\n",
            "ROC AUC: 0.9892519936517361\n",
            "Confusion Matrix:\n",
            " [[50013   131]\n",
            " [ 1677 48179]]\n",
            "\n",
            "Random Forest Classifier Metrics:\n",
            "Accuracy: 0.99991\n",
            "F1-Score: 0.9999100000225991\n",
            "ROC AUC: 0.9999999701997528\n",
            "Confusion Matrix:\n",
            " [[50135     9]\n",
            " [    0 49856]]\n",
            "\n",
            "Process Completed - Time: 2:04:08.030482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "Dataset Loaded - Time Elapsed: 3:21:22.933973\n",
        "Labeling Function Applied - Time Elapsed: 3:21:23.043958\n",
        "Categorical Labels Encoded - Time Elapsed: 3:21:23.064381\n",
        "Logistic Regression Trained - Time Elapsed: 3:21:23.266569\n",
        "Logistic Regression Metrics:\n",
        "Accuracy: 0.9955\n",
        "F1-Score: 0.9955117559971776\n",
        "ROC AUC: 0.9998803509535648\n",
        "Confusion Matrix:\n",
        " [[1454    9]\n",
        " [   0  537]]\n",
        "\n",
        "Random Forest Classifier Metrics:\n",
        "Accuracy: 0.9985\n",
        "F1-Score: 0.9985013193793913\n",
        "ROC AUC: 1.0\n",
        "Confusion Matrix:\n",
        " [[1460    3]\n",
        " [   0  537]]\n",
        "\n",
        "Process Completed - Time: 3:21:24.437783\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ujl2eaCfHeIj",
        "outputId": "3137b9a8-0753-445a-e561-f129f33fb4f2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "malicious    250719\n",
            "normal       249281\n",
            "Name: traffic_label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "SBy7yifELB3a",
        "outputId": "9292f961-1f04-40d2-c133-e929aee0d2ce"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   flow_key  src_ip_numeric  src_ip  src_port  dst_ip  dst_port  proto  \\\n",
              "0     50398    3.232266e+09       0      67.0    2162      67.0   17.0   \n",
              "1    130265    3.232266e+09       0      67.0    2163      67.0   17.0   \n",
              "2     50398    3.232266e+09       0      67.0    2162      67.0   17.0   \n",
              "3    130265    3.232266e+09       0      67.0    2163      67.0   17.0   \n",
              "4    178728    3.232266e+09       0       0.0      22       0.0    1.0   \n",
              "\n",
              "   pktTotalCount  octetTotalCount  min_ps  ...  b_flowDuration  b_min_piat  \\\n",
              "0           22.0           7620.0   328.0  ...    1.550000e+12    0.010354   \n",
              "1           17.0           5670.0   328.0  ...    0.000000e+00    0.000000   \n",
              "2           43.0          15124.0   328.0  ...    1.550000e+12    0.022332   \n",
              "3           30.0          10086.0   328.0  ...    0.000000e+00    0.000000   \n",
              "4            1.0             56.0    56.0  ...    0.000000e+00    0.000000   \n",
              "\n",
              "   b_max_piat  b_avg_piat  b_std_dev_piat  flowEndReason  category  \\\n",
              "0  198.657965   51.689181       84.916348            2.0        10   \n",
              "1    0.000000    0.000000        0.000000            2.0        10   \n",
              "2  340.268454   89.927588      124.270745            2.0        10   \n",
              "3    0.000000    0.000000        0.000000            2.0        10   \n",
              "4    0.000000    0.000000        0.000000            2.0        10   \n",
              "\n",
              "   application_protocol  web_service  traffic_label  \n",
              "0                    12           11         normal  \n",
              "1                    12           11         normal  \n",
              "2                    12           11         normal  \n",
              "3                    12           11         normal  \n",
              "4                    12           30         normal  \n",
              "\n",
              "[5 rows x 51 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22ad85e6-d205-4ed9-91ea-cbbd101c856a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>flow_key</th>\n",
              "      <th>src_ip_numeric</th>\n",
              "      <th>src_ip</th>\n",
              "      <th>src_port</th>\n",
              "      <th>dst_ip</th>\n",
              "      <th>dst_port</th>\n",
              "      <th>proto</th>\n",
              "      <th>pktTotalCount</th>\n",
              "      <th>octetTotalCount</th>\n",
              "      <th>min_ps</th>\n",
              "      <th>...</th>\n",
              "      <th>b_flowDuration</th>\n",
              "      <th>b_min_piat</th>\n",
              "      <th>b_max_piat</th>\n",
              "      <th>b_avg_piat</th>\n",
              "      <th>b_std_dev_piat</th>\n",
              "      <th>flowEndReason</th>\n",
              "      <th>category</th>\n",
              "      <th>application_protocol</th>\n",
              "      <th>web_service</th>\n",
              "      <th>traffic_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50398</td>\n",
              "      <td>3.232266e+09</td>\n",
              "      <td>0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>2162</td>\n",
              "      <td>67.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>7620.0</td>\n",
              "      <td>328.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.550000e+12</td>\n",
              "      <td>0.010354</td>\n",
              "      <td>198.657965</td>\n",
              "      <td>51.689181</td>\n",
              "      <td>84.916348</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>130265</td>\n",
              "      <td>3.232266e+09</td>\n",
              "      <td>0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>2163</td>\n",
              "      <td>67.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>5670.0</td>\n",
              "      <td>328.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50398</td>\n",
              "      <td>3.232266e+09</td>\n",
              "      <td>0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>2162</td>\n",
              "      <td>67.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>15124.0</td>\n",
              "      <td>328.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.550000e+12</td>\n",
              "      <td>0.022332</td>\n",
              "      <td>340.268454</td>\n",
              "      <td>89.927588</td>\n",
              "      <td>124.270745</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>130265</td>\n",
              "      <td>3.232266e+09</td>\n",
              "      <td>0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>2163</td>\n",
              "      <td>67.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10086.0</td>\n",
              "      <td>328.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>178728</td>\n",
              "      <td>3.232266e+09</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>30</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 51 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22ad85e6-d205-4ed9-91ea-cbbd101c856a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-22ad85e6-d205-4ed9-91ea-cbbd101c856a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-22ad85e6-d205-4ed9-91ea-cbbd101c856a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c81f55bf-5c12-420a-90f3-36da1be31886\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c81f55bf-5c12-420a-90f3-36da1be31886')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c81f55bf-5c12-420a-90f3-36da1be31886 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "file_path_full = 'Unicauca-dataset-April-June-2019-Network-flows-25000rows(ALLFEATURES).csv'\n",
        "df_full = pd.read_csv(file_path_full)\n",
        "\n",
        "# Lists of normal web services, application protocols, and categories\n",
        "normal_web_services = ['Google', 'Microsoft', 'HTTP', 'DNS', 'Amazon', 'MSN', 'TLS', 'Yahoo', 'DHCP',\n",
        "                       'WindowsUpdate', 'NetBIOS', 'RX', 'MS_OneDrive', 'GMail', 'Dropbox', 'GoogleServices', 'ICMP',\n",
        "                       'UbuntuONE', 'GoogleDrive', 'YouTube', 'HTTP_Proxy', 'NTP', 'Apple', 'AppleiTunes', 'AppleStore',\n",
        "                       'ApplePush', 'AppleiCloud', 'IMAPS', 'IMO', 'Office365', 'Skype', 'Cloudflare']\n",
        "\n",
        "normal_application_protocols = ['HTTP', 'TLS', 'DNS', 'QUIC', 'IMAPS', 'STUN', 'SMTPS', 'POPS', 'Skype', 'SMBv23',\n",
        "                                 'NetBIOS', 'RDP', 'ApplePush', 'MQTT']\n",
        "\n",
        "normal_categories = ['Network', 'Unknown', 'Web', 'SoftwareUpdate', 'RPC', 'System', 'Cloud', 'Mail', 'FTP', 'VPN',\n",
        "                     'RemoteAccess', 'Email', 'Media', 'Streaming', 'Unkown', 'VoIP', 'Collaborative']\n",
        "\n",
        "# Check uniqueness in the dataset\n",
        "unique_web_services = df_full['web_service'].unique().tolist()\n",
        "unique_application_protocols = df_full['application_protocol'].unique().tolist()\n",
        "unique_categories = df_full['category'].unique().tolist()\n",
        "\n",
        "# Verify if the listed items are unique in the dataset\n",
        "unique_web_services_check = all(service in normal_web_services for service in unique_web_services)\n",
        "unique_application_protocols_check = all(protocol in normal_application_protocols for protocol in unique_application_protocols)\n",
        "unique_categories_check = all(category in normal_categories for category in unique_categories)\n",
        "print(\"unique_web_services_check\", unique_web_services)\n",
        "\n",
        "print(\"unique_application_protocols_check\", unique_application_protocols)\n",
        "print(\"unique_categories_check\", unique_categories)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cmq9xR_CS5l-",
        "outputId": "6468b630-3955-4bce-cc60-fce948d4fa49"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique_web_services_check ['DHCP', 'ICMP', 'HTTP', 'Microsoft', 'WindowsUpdate', 'Unknown', 'DNS', 'RX', 'TLS', 'NetBIOS', 'GoogleServices', 'Amazon', 'MSN', 'Yahoo', 'MS_OneDrive', 'Google', 'Dropbox', 'GMail', 'UbuntuONE', 'GoogleDrive', 'YouTube', 'HTTP_Proxy', 'NTP', 'Apple', 'AppleiTunes', 'AppleStore', 'ApplePush', 'AppleiCloud', 'IMAPS', 'IMO', 'Office365', 'Skype', 'Cloudflare', 'Spotify', 'LDAP', 'Twitter', 'Facebook', 'LinkedIn', 'Instagram', 'AmazonVideo', 'GooglePlus', 'Github', 'GoogleDocs', 'Teredo', 'BitTorrent', 'Messenger', 'WhatsApp', 'PlayStore', 'Ookla', 'Unencrypted_Jabber', 'SMBv23', 'Wikipedia', 'QUIC', 'Signal', 'CiscoVPN', 'TeamViewer', 'VNC', 'NetFlix', 'Playstation', 'PS_VUE', 'Xbox', 'GoogleMaps', 'GoogleHangoutDuo', 'MQTT', 'Radius', 'SSH', 'STUN', 'Pando_Media_Booster', 'Whois-DAS', 'H323', 'Webex', 'Oracle', 'DataSaver', 'Steam', 'Telegram', 'Mining', 'SNMP', 'WhatsAppCall', 'Syslog', 'Starcraft', 'IPsec', 'SIP', 'RDP', 'MsSQL-TDS', 'OpenDNS', 'SkypeCall', 'Tor', 'RTMP', 'QQ', 'IRC', 'Slack', 'eBay', 'HotspotShield', 'TikTok', 'Snapchat', 'SSDP', 'DNSoverHTTPS', 'SMTP', 'RTP', 'WeChat', 'Targus Dataspeed', 'BJNP', nan]\n",
            "unique_application_protocols_check ['Unknown', 'HTTP', 'TLS', 'DNS', 'QUIC', 'IMAPS', 'STUN', 'SMTPS', 'POPS', 'Skype', 'BitTorrent', 'SMBv23', 'NetBIOS', nan]\n",
            "unique_categories_check ['Network', 'Web', 'SoftwareUpdate', 'Unspecified', 'RPC', 'System', 'Cloud', 'Email', 'Media', 'Streaming', 'VoIP', 'Collaborative', 'Music', 'SocialNetwork', 'Video', 'Download-FileTransfer-FileSharing', 'Chat', 'VPN', 'RemoteAccess', 'Game', 'Database', 'Mining', 'Shopping', nan]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Function to record the current time since the overall start\n",
        "def record_time(step_name, overall_start_time):\n",
        "    print(f\"{step_name} - Time Elapsed: {datetime.datetime.now() - overall_start_time}\")\n",
        "\n",
        "# Apply the modified labeling function to label the traffic data\n",
        "def label_traffic(df):\n",
        "    # Define normal thresholds\n",
        "    normal_protocols = [6, 17, 1]  # TCP and UDP\n",
        "    normal_port_range = set(range(0, 65536))\n",
        "    normal_pkt_count_max = 50\n",
        "    normal_octet_count_max = 15000\n",
        "    normal_packet_size_range = range(20, 1500)\n",
        "    normal_std_dev_ps_range = range(9, 27)\n",
        "    normal_min_piat_range = range(0, int(0.010356 * 1e6))\n",
        "    normal_max_piat_range = range(158, 249)\n",
        "    normal_avg_piat_range = range(1, 107)\n",
        "    normal_std_dev_piat_range = range(50, 79)\n",
        "    normal_avg_ps_range = range(20, 1500)  # Define the range based on your analysis\n",
        "    normal_flow_duration_range = range(1451, 1702)\n",
        "    max_timestamp = int(1e12)\n",
        "\n",
        "    # Initialize the traffic_label column\n",
        "    df['traffic_label'] = 'normal'\n",
        "\n",
        "    # Vectorized conditions\n",
        "    df.loc[~df['avg_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_ps'].isin(normal_std_dev_ps_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['flowDuration'].isin(normal_flow_duration_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['min_piat'].isin(normal_min_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['max_piat'].isin(normal_max_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['avg_piat'].isin(normal_avg_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_piat'].isin(normal_std_dev_piat_range), 'traffic_label'] = 'malicious'\n",
        "\n",
        "    df.loc[(df['flowStart'] < 0) | (df['flowStart'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[(df['flowEnd'] < 0) | (df['flowEnd'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['flowEnd'] < df['flowStart'], 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # Forward flow features conditions\n",
        "    for prefix in ['f_']:\n",
        "        df.loc[df[prefix + 'pktTotalCount'] > normal_pkt_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[df[prefix + 'octetTotalCount'] > normal_octet_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_ps'].isin(normal_avg_ps_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_ps'].isin(normal_std_dev_ps_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'flowDuration'].isin(normal_flow_duration_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'min_piat'].isin(normal_min_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'max_piat'].isin(normal_max_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_piat'].isin(normal_avg_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_piat'].isin(normal_std_dev_piat_range), 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # IP Address checks\n",
        "    normal_src_ip_ranges = ['192.168.', '10.', '172.16.', '172.17.', '172.18.', '172.19.', '172.20.', '172.21.', '172.22.', '172.23.', '172.24.', '172.25.', '172.26.', '172.27.', '172.28.', '172.29.', '172.30.', '172.31.']\n",
        "    # Convert 'dst_ip' column to string\n",
        "    df['dst_ip'] = df['dst_ip'].astype(str)\n",
        "\n",
        "    # Apply IP address conditions\n",
        "    df.loc[df['dst_ip'].apply(lambda ip: any(ip.startswith(range) for range in normal_src_ip_ranges)), 'traffic_label'] = 'normal'\n",
        "\n",
        "    # Web service, application protocol, and category checks\n",
        "    df.loc[~df['web_service'].isin(normal_web_services), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['application_protocol'].isin(normal_application_protocols), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['category'].isin(normal_categories), 'traffic_label'] = 'malicious'\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Load your dataset here (replace 'your_dataset.csv' with the actual file path)\n",
        "df = pd.read_csv('Unicauca-dataset-April-June-2019-Network-flows-10000rows(ALLFEATURES).csv')\n",
        "record_time(\"Dataset Loaded\", overall_start_time)\n",
        "\n",
        "# Apply the modified labeling function to label the traffic data\n",
        "df = label_traffic(df)\n",
        "record_time(\"Labeling Function Applied\", overall_start_time)\n",
        "\n",
        "# Drop features based on the analysis\n",
        "features_to_drop = ['src_ip', 'flow_key', 'flowDuration', 'min_ps', 'max_ps'] + [col for col in df.columns if col.startswith('b_')]\n",
        "df = df.drop(columns=features_to_drop)\n",
        "\n",
        "# Modified preprocessing step\n",
        "# Identify all categorical columns (excluding the target variable)\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
        "categorical_columns.remove('traffic_label')\n",
        "\n",
        "# Apply label encoding to each categorical column\n",
        "label_encoder = LabelEncoder()\n",
        "for col in categorical_columns:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "record_time(\"Categorical Labels Encoded\", overall_start_time)\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = df.drop(columns=['traffic_label'])\n",
        "y = df['traffic_label']\n",
        "\n",
        "# Handle NaN values by imputation\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Standardize numeric features\n",
        "scaler = StandardScaler()\n",
        "numeric_columns = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "X_imputed = pd.DataFrame(X_imputed, columns=X.columns)\n",
        "X_imputed[numeric_columns] = scaler.fit_transform(X_imputed[numeric_columns])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "logistic_regression = LogisticRegression()\n",
        "logistic_regression.fit(X_train, y_train)\n",
        "record_time(\"Logistic Regression Trained\", overall_start_time)\n",
        "\n",
        "# Predict using the Logistic Regression model\n",
        "y_pred_lr = logistic_regression.predict(X_test)\n",
        "\n",
        "# Evaluate the Logistic Regression model\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
        "roc_auc_lr = roc_auc_score(y_test,logistic_regression.predict_proba(X_test)[:, 1])\n",
        "confusion_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "\n",
        "# Print evaluation metrics for Logistic Regression\n",
        "print(\"Logistic Regression Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_lr)\n",
        "print(\"F1-Score:\", f1_lr)\n",
        "print(\"ROC AUC:\", roc_auc_lr)\n",
        "print(\"Confusion Matrix:\\n\", confusion_lr)\n",
        "\n",
        "# Create and train the RandomForestClassifier model\n",
        "random_forest = RandomForestClassifier()\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the RandomForestClassifier model\n",
        "y_pred_rf = random_forest.predict(X_test)\n",
        "\n",
        "# Evaluate the RandomForestClassifier model\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "roc_auc_rf = roc_auc_score(y_test, random_forest.predict_proba(X_test)[:, 1])\n",
        "confusion_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "# Print evaluation metrics for RandomForestClassifier\n",
        "print(\"\\nRandom Forest Classifier Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_rf)\n",
        "print(\"F1-Score:\", f1_rf)\n",
        "print(\"ROC AUC:\", roc_auc_rf)\n",
        "print(\"Confusion Matrix:\\n\", confusion_rf)\n",
        "print(\"\\nProcess Completed - Time:\", datetime.datetime.now() - overall_start_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ed9356WW6aN",
        "outputId": "11cd810e-057a-4a3f-f901-5fcd946ea768"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded - Time Elapsed: 3:21:22.933973\n",
            "Labeling Function Applied - Time Elapsed: 3:21:23.043958\n",
            "Categorical Labels Encoded - Time Elapsed: 3:21:23.064381\n",
            "Logistic Regression Trained - Time Elapsed: 3:21:23.266569\n",
            "Logistic Regression Metrics:\n",
            "Accuracy: 0.9955\n",
            "F1-Score: 0.9955117559971776\n",
            "ROC AUC: 0.9998803509535648\n",
            "Confusion Matrix:\n",
            " [[1454    9]\n",
            " [   0  537]]\n",
            "\n",
            "Random Forest Classifier Metrics:\n",
            "Accuracy: 0.9985\n",
            "F1-Score: 0.9985013193793913\n",
            "ROC AUC: 1.0\n",
            "Confusion Matrix:\n",
            " [[1460    3]\n",
            " [   0  537]]\n",
            "\n",
            "Process Completed - Time: 3:21:24.437783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Method 1: Value Counts\n",
        "print(\"Class distribution in y:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "print(\"\\nClass distribution in y_train:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "# Method 2: Unique Values\n",
        "print(\"\\nUnique classes in y:\")\n",
        "print(np.unique(y))\n",
        "\n",
        "print(\"\\nUnique classes in y_train:\")\n",
        "print(np.unique(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEl5FVtIa4y-",
        "outputId": "e1a985fb-336c-41b9-cf60-1d083684ea5d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution in y:\n",
            "malicious    7314\n",
            "normal       2686\n",
            "Name: traffic_label, dtype: int64\n",
            "\n",
            "Class distribution in y_train:\n",
            "malicious    5851\n",
            "normal       2149\n",
            "Name: traffic_label, dtype: int64\n",
            "\n",
            "Unique classes in y:\n",
            "['malicious' 'normal']\n",
            "\n",
            "Unique classes in y_train:\n",
            "['malicious' 'normal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "import datetime\n",
        "\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Function to record the current time since the overall start\n",
        "def record_time(step_name, overall_start_time):\n",
        "    print(f\"{step_name} - Time Elapsed: {datetime.datetime.now() - overall_start_time}\")\n",
        "\n",
        "# Apply the modified labeling function to label the traffic data\n",
        "def label_traffic(df):\n",
        "    # Define normal thresholds\n",
        "    normal_protocols = [6, 17, 1]  # TCP and UDP\n",
        "    normal_port_range = set(range(0, 65536))\n",
        "    normal_pkt_count_max = 50\n",
        "    normal_octet_count_max = 15000\n",
        "    normal_packet_size_range = range(20, 1500)\n",
        "    normal_std_dev_ps_range = range(9, 27)\n",
        "    normal_min_piat_range = range(0, int(0.010356 * 1e6))\n",
        "    normal_max_piat_range = range(158, 249)\n",
        "    normal_avg_piat_range = range(1, 107)\n",
        "    normal_std_dev_piat_range = range(50, 79)\n",
        "    normal_avg_ps_range = range(20, 1500)  # Define the range based on your analysis\n",
        "    normal_flow_duration_range = range(1451, 1702)\n",
        "    max_timestamp = int(1e12)\n",
        "\n",
        "    # Initialize the traffic_label column\n",
        "    df['traffic_label'] = 'normal'\n",
        "\n",
        "    # Vectorized conditions\n",
        "    df.loc[~df['avg_ps'].isin(normal_packet_size_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_ps'].isin(normal_std_dev_ps_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['flowDuration'].isin(normal_flow_duration_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['min_piat'].isin(normal_min_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['max_piat'].isin(normal_max_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['avg_piat'].isin(normal_avg_piat_range), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['std_dev_piat'].isin(normal_std_dev_piat_range), 'traffic_label'] = 'malicious'\n",
        "\n",
        "    df.loc[(df['flowStart'] < 0) | (df['flowStart'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[(df['flowEnd'] < 0) | (df['flowEnd'] > max_timestamp), 'traffic_label'] = 'malicious'\n",
        "    df.loc[df['flowEnd'] < df['flowStart'], 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # Forward flow features conditions\n",
        "    for prefix in ['f_']:\n",
        "        df.loc[df[prefix + 'pktTotalCount'] > normal_pkt_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[df[prefix + 'octetTotalCount'] > normal_octet_count_max, 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_ps'].isin(normal_avg_ps_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_ps'].isin(normal_std_dev_ps_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'flowDuration'].isin(normal_flow_duration_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'min_piat'].isin(normal_min_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'max_piat'].isin(normal_max_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'avg_piat'].isin(normal_avg_piat_range), 'traffic_label'] = 'malicious'\n",
        "        df.loc[~df[prefix + 'std_dev_piat'].isin(normal_std_dev_piat_range), 'traffic_label'] = 'malicious'\n",
        "\n",
        "    # IP Address checks\n",
        "    normal_src_ip_ranges = ['192.168.', '10.', '172.16.', '172.17.', '172.18.', '172.19.', '172.20.', '172.21.', '172.22.', '172.23.', '172.24.', '172.25.', '172.26.', '172.27.', '172.28.', '172.29.', '172.30.', '172.31.']\n",
        "    # Convert 'dst_ip' column to string\n",
        "    df['dst_ip'] = df['dst_ip'].astype(str)\n",
        "\n",
        "    # Apply IP address conditions\n",
        "    df.loc[df['dst_ip'].apply(lambda ip: any(ip.startswith(range) for range in normal_src_ip_ranges)), 'traffic_label'] = 'normal'\n",
        "\n",
        "    # Web service, application protocol, and category checks\n",
        "    df.loc[~df['web_service'].isin(normal_web_services), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['application_protocol'].isin(normal_application_protocols), 'traffic_label'] = 'malicious'\n",
        "    df.loc[~df['category'].isin(normal_categories), 'traffic_label'] = 'malicious'\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Load your dataset here (replace 'your_dataset.csv' with the actual file path)\n",
        "df = pd.read_csv('Unicauca-dataset-April-June-2019-Network-flows-10000rows(ALLFEATURES).csv')\n",
        "record_time(\"Dataset Loaded\", overall_start_time)\n",
        "\n",
        "# Apply the modified labeling function to label the traffic data\n",
        "df = label_traffic(df)\n",
        "record_time(\"Labeling Function Applied\", datetime.datetime.now())\n",
        "\n",
        "# Define the features to retain based on analysis\n",
        "features_to_retain = [\n",
        "    'src_ip_numeric', 'src_port', 'dst_port', 'proto',\n",
        "    'pktTotalCount', 'octetTotalCount', 'avg_ps', 'std_dev_ps',\n",
        "    'min_piat', 'max_piat', 'avg_piat', 'std_dev_piat',\n",
        "    'f_pktTotalCount', 'f_octetTotalCount', 'f_avg_ps', 'f_std_dev_ps',\n",
        "    'flowEndReason', 'category', 'application_protocol', 'web_service'\n",
        "]\n",
        "\n",
        "# Preprocessing\n",
        "X = df[features_to_retain]\n",
        "y = df['traffic_label']  # Assuming 'traffic_label' is your target variable\n",
        "\n",
        "# Encode categorical columns\n",
        "label_encoder = LabelEncoder()\n",
        "categorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n",
        "for col in categorical_columns:\n",
        "    X[col] = label_encoder.fit_transform(X[col])\n",
        "record_time(\"Categorical Columns Encoded\", overall_start_time)\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_standardized = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_standardized, y, test_size=0.2, random_state=42, stratify=y)\n",
        "record_time(\"Dataset Split\", overall_start_time)\n",
        "\n",
        "# Initialize StratifiedKFold for cross-validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize metrics\n",
        "accuracy_lr_list = []\n",
        "f1_lr_list = []\n",
        "roc_auc_lr_list = []\n",
        "accuracy_rf_list = []\n",
        "f1_rf_list = []\n",
        "roc_auc_rf_list = []\n",
        "\n",
        "# Perform Stratified Cross-Validation\n",
        "for train_index, test_index in skf.split(X_train, y_train):\n",
        "    X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
        "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "\n",
        "    # Apply SMOTE for oversampling\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_smote, y_train_smote = smote.fit_resample(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Train Logistic Regression\n",
        "    logistic_regression = LogisticRegression(class_weight='balanced')\n",
        "    logistic_regression.fit(X_train_smote, y_train_smote)\n",
        "    y_pred_lr = logistic_regression.predict(X_test_fold)\n",
        "    accuracy_lr_list.append(accuracy_score(y_test_fold, y_pred_lr))\n",
        "    f1_lr_list.append(f1_score(y_test_fold, y_pred_lr, average='weighted'))\n",
        "    roc_auc_lr_list.append(roc_auc_score(y_test_fold, logistic_regression.predict_proba(X_test_fold)[:, 1]))\n",
        "\n",
        "    # Train Random Forest Classifier\n",
        "    random_forest = RandomForestClassifier(class_weight='balanced_subsample')\n",
        "    random_forest.fit(X_train_smote, y_train_smote)\n",
        "    y_pred_rf = random_forest.predict(X_test_fold)\n",
        "    accuracy_rf_list.append(accuracy_score(y_test_fold, y_pred_rf))\n",
        "    f1_rf_list.append(f1_score(y_test_fold, y_pred_rf, average='weighted'))\n",
        "    roc_auc_rf_list.append(roc_auc_score(y_test_fold, random_forest.predict_proba(X_test_fold)[:, 1]))\n",
        "\n",
        "# Calculate and print average metrics\n",
        "print(\"Average Logistic Regression Metrics:\")\n",
        "print(\"Accuracy:\", sum(accuracy_lr_list) / len(accuracy_lr_list))\n",
        "print(\"F1-Score:\", sum(f1_lr_list) / len(f1_lr_list))\n",
        "print(\"ROC AUC:\", sum(roc_auc_lr_list) / len(roc_auc_lr_list))\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nAverage Random Forest Classifier Metrics:\")\n",
        "print(\"Accuracy:\", sum(accuracy_rf_list) / len(accuracy_rf_list))\n",
        "print(\"F1-Score:\", sum(f1_rf_list) / len(f1_rf_list))\n",
        "print(\"ROC AUC:\", sum(roc_auc_rf_list) / len(roc_auc_rf_list))\n",
        "\n",
        "print(\"\\nProcess Completed - Time:\", datetime.datetime.now() - overall_start_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h5-8Q2YbjEH",
        "outputId": "829c7c9b-5834-468a-ab77-66882de09f35"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded - Time Elapsed: 3:53:58.117471\n",
            "Labeling Function Applied - Time Elapsed: 0:00:00.000007\n",
            "Categorical Columns Encoded - Time Elapsed: 3:53:58.355221\n",
            "Dataset Split - Time Elapsed: 3:53:58.405117\n",
            "Average Logistic Regression Metrics:\n",
            "Accuracy: 0.99725\n",
            "F1-Score: 0.997255625736423\n",
            "ROC AUC: 0.9999113208996235\n",
            "\n",
            "Average Random Forest Classifier Metrics:\n",
            "Accuracy: 0.9985000000000002\n",
            "F1-Score: 0.9985017313905657\n",
            "ROC AUC: 0.9999984098588749\n",
            "\n",
            "Process Completed - Time: 3:54:15.176972\n"
          ]
        }
      ]
    }
  ]
}